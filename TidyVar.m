(* ::Package:: *)

(************************************************************************)
(* This file was generated automatically by the Mathematica front end.  *)
(* It contains Initialization cells from a Notebook file, which         *)
(* typically will have the same name as this file except ending in      *)
(* ".nb" instead of ".m".                                               *)
(*                                                                      *)
(* This file is intended to be loaded into the Mathematica kernel using *)
(* the package loading commands Get or Needs.  Doing so is equivalent   *)
(* to using the Evaluate Initialization Cells menu command in the front *)
(* end.                                                                 *)
(*                                                                      *)
(* DO NOT EDIT THIS FILE.  This entire file is regenerated              *)
(* automatically each time the parent Notebook file is saved in the     *)
(* Mathematica front end.  Any changes you make to this file will be    *)
(* overwritten.                                                         *)
(************************************************************************)



BeginPackage["TidyVar`"];


$TidyVarVersion="0.2.4";


WriteString["stdout","TidyVar package for calling genomic variants from Next Generation Sequencing data.\nVersion ",$TidyVarVersion,"\nBoris Noyvert, Greg Elgar lab, 2014-2016.\n"];
If[$OperatingSystem==="Windows",WriteString["stdout","Sorry, TidyVar doesn't work under Windows operating system, please try it on Linux or MacOS.\n"](*;Abort[]*)];


CallVariants


MakeCoordinateString


ExtractCoordinatesFromString


GetSequenceFromGenomeFasta


FindAllelesAndCountReads


ScanForVariantCandidates


GetReadsFromBamFiles


OptimiseTargets


CheckFileExistence


CheckSamtoolsIsInstalled


CheckBamIsIndexed


CheckBamFiles


SamtoolsPath


GenomeFastaFile


FastaFileName


ExtendTargetsBy


MinimalCoverage


MinimalNumberNonreferenceReads


MinimalRatioNonreferenceReads


MinimalBaseSequencingScore


MinimalReadMappingScore


SamtoolsFlagFilter


LogFileName


FailedLogFileName


SaveCoverage


PlotClusteredReadCounts2D


GenotypeReadCounts


LoadVCF


LastVCFHeader


ConvertVcfLineToVariant


ConvertVariantToVcfLine


RemoveDummyAlleles


Begin["`Private`"];


MakeCoordinateString::usage="MakeCoordinateString converts a list in the form {chr,coord1,coord2} or {chr,{coord1,coord2}} into a string \"'chr:coord1-coord2'\".
If the argument of the function is already a string, then the function doesn't change it.
If there is only one argument (chr) the function returns it in the string form.";
MakeCoordinateString[""]:="";
MakeCoordinateString[x_String]:=Block[{trimmed},trimmed=StringTrim[x,("'"|" "|"\t"|"\"")..];
If[trimmed==="","","'"<>trimmed<>"'"]];
MakeCoordinateString[x__]:=Module[{arg,l},arg=ToString/@Flatten[{x}];
l=Length[arg];"'"<>arg[[1]]<>Which[l==1,"",l==2,":"<>arg[[2]],l>=3,":"<>arg[[2]]<>"-"<>arg[[3]]]<>"'"];


ExtractCoordinatesFromString::usage="ExtractCoordinatesFromString extracts coordinates in the form {chr,coord1,coord2} from a string like \"'chr:coord1-coord2'\"";
ExtractCoordinatesFromString[x_String]:=Module[{trimmedandsplitted},
trimmedandsplitted=StringSplit[StringTrim[x,("'"|" "|"\t"|"\"")..],{":","-"}];
If[Length[trimmedandsplitted]>=3,Flatten[{trimmedandsplitted[[1]],FromDigits/@trimmedandsplitted[[2;;3]]}],
trimmedandsplitted]
]


GetSequenceFromGenomeFasta::usage="GetSequenceFromGenomeFasta[coordinates__, FastaFileName\[Rule]GenomeFastaFile].
GetSequenceFromGenomeFasta uses 'samtools faidx' to extract the genomic sequence corresponding to the given coordinates from the fasta file.
The fasta file name can be supplied using FastaFileName option. By default it is set to GenomeFastaFile - so you can set this variable from the beginning and forget about it. If the fasta file is not found the computation is aborted.";
Options[GetSequenceFromGenomeFasta]={FastaFileName->GenomeFastaFile};
GetSequenceFromGenomeFasta[x__,OptionsPattern[GetSequenceFromGenomeFasta]]:=Module[{region,cmd,samtoolsrunresult},
CheckFileExistence[OptionValue[FastaFileName]];
region=MakeCoordinateString[x];cmd=StringJoinWith[{SamtoolsPath<>"samtools faidx",OptionValue[FastaFileName],region}];
samtoolsrunresult=RunExternal[cmd,String];
StringJoin[Drop[samtoolsrunresult,1]]
];


CheckFileExistence::usage="CheckFileExistence[filename_].
If filename is not a string or is a string but there is no file with this name, then the computation is aborted.";
CheckFileExistence[filename_]:=If[!StringQ[filename],
PrintError["The file name argument must be a string!\nAborting!"];Abort[],
If[!FileExistsQ[filename],
PrintError["File\n",filename,"\nis not found!\nAborting!"];Abort[],
True]
];


StringJoinWith[x_List,rifflestring_String:" "]:=StringJoin[Riffle[ToString/@Flatten[x],rifflestring]];

MakeTableString[x_List]:=StringJoinWith[StringJoinWith[#,"\t"]&/@x,"\n"]


RunExternal::usage="RunExternal[command_String, types_:\"String\", op:OptionsPattern[ReadList]] basically calls ReadList built-in function.
It runs external (Linux) command and loads its result as a table of elements of specified types, e.g. {Number, Word, Word}.
In Mathematica 10 and later there is a problem with the management of virtual memory, so the result is first saved in a temporary file and then loaded into Mathematica.";
Options[RunExternal]={TmpDirectory->TidyVarTmpDirectory};
RunExternal[command_String,Optional[types:PatternTest[_,FreeQ[#,Rule]&],"String"],op:OptionsPattern[{ReadList,RunExternal}]]:=Module[{tmpfile,result,code,opRL},
opRL=FilterRules[{op},Options[ReadList]];
If[$VersionNumber<9.5,
Return[ReadList["!"<>command,types,opRL]]];
tmpfile=FileNameJoin[{OptionValue[TmpDirectory],"runexternal_temp_"<>FromCharacterCode[RandomInteger[{97,122},10]]}];
code=Run[command<>" > "<>tmpfile];
result=If[code=!=0,
"Wrong command, code:"<>ToString[code],
ReadList[tmpfile,types,opRL]];
DeleteFile[tmpfile];
result
];


IntersectionPositionsSimple[d1_List,d2_List]:=Module[{int,res},
int=Intersection[d1,d2];
res=Join@@Outer[List,Join@@Position[d1,#,{1},Heads->False],Join@@Position[d2,#,{1},Heads->False]]&/@int;
Join@@res//Sort
];


AppendFileName[filename_String,app_String,extension_String:"same"]:=
Module[{ext,fileparts},
If[extension==="same",ext="."<>FileExtension[filename],If[extension==="",ext="",ext="."<>extension]];
fileparts={DirectoryName[filename],FileBaseName[filename]<>app<>ext};
If[fileparts[[1]]==="",fileparts=Drop[fileparts,1]];
fileparts//FileNameJoin
]


Options[RenameFileForced]={KeepOldFile->True};
RenameFileForced[file1_String,file2_String,OptionsPattern[RenameFileForced]]:=Module[{old},

CheckFileExistence[file1];

If[file1===file2,
Print[Style["File names are identical!",Red//Darker]];
Return[file1]
];


If[FileExistsQ[file2],
If[OptionValue[KeepOldFile],
(old=AppendFileName[file2,".old",""];
If[DirectoryQ[file1],
(
If[FileExistsQ[old],DeleteDirectory[old,DeleteContents->True]]),
(
If[FileExistsQ[old],DeleteFile[old]])];
RenameFile[file2,old]
),
DeleteFile[file2]]
];
RenameFile[file1,file2]
]


(* 
Joins all subsequent regions with distance between them less or equal to OptionValue[CombineDistance].
Input is in a form of list of pairs of numbers.
*)
Options[CombineRegions]={ApplySort->True,CombineDistance->1};

CombineRegions[{}]={};
CombineRegions[regions_?MatrixQ,OptionsPattern[CombineRegions]]:=Module[{dist,xxx,xxxcoord,ps,pscomb,pscomb1,pscomb2,res},
dist=OptionValue[CombineDistance];
(*clmn=OptionValue[Columns];*)
xxx=If[OptionValue[ApplySort],Sort[regions],regions];
ps=Join@@Position[Sign[xxx[[2;;-1,1]]-xxx[[1;;-2,2]]-dist-0.000001],-1,{1},Heads->False];
pscomb={0,1}+#&/@CombineIntegers[ps,ApplySort->False];

pscomb1=(Table[(Range@@#),{2}]//Transpose)&/@Transpose[{Prepend[pscomb[[All,2]]+1,1],Append[pscomb[[All,1]]-1,Length[xxx]]}];

pscomb2=Join@@Riffle[pscomb1,List/@pscomb];

res=Transpose[{Min/@#,Max/@#}]&@Table[Take[xxx,rrr],{rrr,pscomb2}];

If[Min[res[[2;;-1,1]]-res[[1;;-2,2]]]>dist,res,
CombineRegions[res,ApplySort->False,CombineDistance->dist]]
];

(*
Converts a list of integers to the ranges of consecutive numbers
*)
Options[CombineIntegers]={ApplySort->True,CombineDistance->1};
CombineIntegers[{},___]={};
CombineIntegers[x_List,OptionsPattern[CombineIntegers]]:=Module[{xx,ps,rd},
xx=If[OptionValue[ApplySort],Union[x],x];
rd=OptionValue[CombineDistance];
ps=Join[{0},Join@@Position[Sign[xx[[2;;-1]]-xx[[1;;-2]]-rd],1,{1},Heads->False],{Length[xx]}];
Map[xx[[#]]&,Transpose[{ps[[1;;-2]]+1,ps[[2;;-1]]}],{2}]
];


PrintError::usage="Prints its arguments using a colour specified (Darker[Red] by default).";
Options[PrintError]={Colour->Darker[Red]};
PrintError[x_String,OptionsPattern[PrintError]]:=If[$Notebooks,
Print[Style[x,OptionValue[Colour]]],
WriteString["stderr",x,"\n"]];
PrintError[x_List,op:OptionsPattern[PrintError]]:=PrintError[StringJoinWith[ToString/@Flatten[x]],op];
PrintError[x__,op:OptionsPattern[PrintError]]:=PrintError[{x},op];


ToNumber[yyy_List]:=ToNumber/@yyy;

ToNumber[x_String]:=If[StringMatchQ[x,NumberString],ToExpression[x],If[StringMatchQ[x,NumberString~~("e"|"E")~~NumberString],(#[[1]] 10^#[[2]])&@(ToExpression/@StringSplit[x,("e"|"E")]),x]];

ToNumber[x_]:=x;


LoadVCF[inputfile_String,OptionsPattern[{NumberOfLines->100000,Columns->All,PrintReports->False}]]:=Module[{stream,rd,ps,nnn,clmn,types,limit,cnt,fff,res,header,scorepos,scorepos1,ll},

nnn=OptionValue[NumberOfLines];
clmn=OptionValue[Columns];

rd=ReadList[inputfile,String,1000];

If[rd==={},Return[{}]];

ps=Join@@Position[rd,x_/;StringMatchQ[x,"#*"],{1},Heads->False]//Max;
stream=OpenRead[inputfile];
If[ps=!=-\[Infinity],
Skip[stream,String,ps-1];
header=(StringSplit[#,"\t",All]&/@ReadList[stream,String,1])[[1]];
ll=Length[header],

header="no vcf file header";
ll=StringSplit[rd[[1]],"\t",All]//Length];

types=Join[{"Word","Number","Word","Word","Word",(*"Number"*)"Word"},Table["Word",{ll-6}]];

If[Head[types[[clmn]]]===Part,Print[Style["Column information is wrong!\nShould be between 1 and "<>ToString[ll]<>"!",Red,Bold]];Return["Wrong columns"]];
limit=10^10/nnn//Round;
cnt=0;

Do[
rd=ReadList[stream,types,nnn,NullWords->True,WordSeparators->{"\t"}];
If[rd==={},Break[]];
cnt++;
fff[cnt]=rd[[All,clmn]]
,{limit}];
Close[stream];
res=Join@@Array[fff,cnt];
If[OptionValue[PrintReports],Print["Loaded ",Length[res]," lines into ",Dimensions[res]," table."]];
LastVCFHeader=If[ps===-\[Infinity],header,header[[clmn]]];
scorepos=Join@@Position[Range[ll][[clmn]],6];
If[scorepos==={},
res,
(scorepos1=scorepos[[1]];
ReplacePart[#,scorepos1->ToNumber[#[[scorepos1]]]]&/@res)]
];


(*
-Log10 with excluded singularity at 0.
*)
Log0[x_,\[Epsilon]_:0.01]:=If[x<\[Epsilon],-Log10[\[Epsilon]],-Log10[x]]


(*
Order of vectors is important!
AlleleVectors[2]={{1.,0.},{0.5,0.5},{0.,1.}};
AlleleVectors[3]={{1.,0.,0.},{0.5,0.5,0.},{0.,1.,0.},{0.5,0.,0.5},{0.,0.5,0.5},{0.,0.,1.}};
*)
AlleleVectors[n_]:=AlleleVectors[n]=Join@@Table[1./2 (IdentityMatrix[n][[j1]]+IdentityMatrix[n][[j2]]),{j1,1,n},{j2,1,j1}];
NormalizedAlleleVectors[n_]:=NormalizedAlleleVectors[n]=#/Norm[#]&/@AlleleVectors[n];

AlleleCombinations[n_]:=AlleleCombinations[n]=Prepend[Join@@Table[{j2,j1},{j1,1,n},{j2,1,j1}],{0,0}];


(*
This function takes a set of vectors and assigns each to the closest allele vector, also substituting the closest allele vector by this vector.
Output: {final substituted list of allele vectors, positions of original vectors in the final list}
*)
ClosestVectors[vect_?MatrixQ]:=Module[{d,n,al,products,perm,nperm,orders,topcombin,perm0,permproducts,permmax,vectororder,productorder,cllct,res},
d=Length[vect[[1]]];
n=Length[vect];
al=Length[AlleleVectors[d]];
If[n>al,Return["Too many vectors!"]];

(* n x al matrix *)
products=(vect/Norm/@vect).Transpose[NormalizedAlleleVectors[d]];
nperm=Binomial[al,al-n]Factorial[n];

If[nperm<1000,
(* If there are not many permutations - check all *)
(perm=Transpose[{Range[n],#}]&/@Permutations[Range[al],{n}]),

(* If there are many permutations - first find the one by assigning vectors in order *)
(vectororder=Reverse[Ordering[Max/@products]];
productorder=Reverse/@(Ordering/@products[[vectororder]]);
cllct={};
Do[Do[If[FreeQ[cllct,zzz],AppendTo[cllct,zzz];Break[]],{zzz,rrr}],{rrr,productorder}];

(* 2^14 = 16K. If less than 15 vectors check the top 2 options for each vector *)
If[n>14,
perm0={},
(orders=Reverse[Ordering[#]]&/@products;
topcombin=Flatten[Outer[List,Sequence@@orders[[All,1;;2]]],n-1];perm0=Pick[topcombin,Length/@DeleteDuplicates/@topcombin,n])];

perm=Transpose[{Range[n],#}]&/@Join[perm0,{cllct[[vectororder//Ordering]]}])
];
(* Find the assignment which produces the maximal total product *)
permproducts=Table[Extract[products,rrr]//Total,{rrr,perm}];
permmax=perm[[Ordering[permproducts,-1]//First]];

res={ReplacePart[AlleleVectors[d],Sequence[#[[2]]->vect[[#[[1]]]]]&/@permmax],permmax[[All,2]]};
Remove[n,al,products,perm,nperm,orders,topcombin,perm0,permproducts,permmax,vectororder,productorder,cllct];
res
]


(*
Function BinomialBestFit clusters l-dimensional vectors based on Multinomial probability. 
Input: a matrix of readcounts (n x l) for n individuals, l alleles.
Output: {n-list of numbers from 1 to k for best clusters,
directions (probabilities) of the best clusters (k x l)}.
Options: 
MinimalProbability should be greater than 0 to avoid Log[0]. Default MinimalProbability 0.01 is a reasonable value.
InitialProbabilities is an important option, defines the directions for intitial clusters. The default ones are given by AlleleVectors[l].
GenotypingCoverage: if an individual has less than this number of reads covering the site than the genotype is not calculated and set to ./. The default value is 1, i.e. only individuals with no reads are not genotyped.
*)
Options[BinomialBestFit]={MinimalProbability->0.01,InitialProbabilities->"Default",
GenotypingCoverage->1,
PrintReports->False};

BinomialBestFit[readcounts0_?MatrixQ,OptionsPattern[BinomialBestFit]]:=Module[{l,p,pinit,plog,\[Epsilon],phred,bestcluster0,bestcluster,ttl,ps0,readcounts,psinsert},
\[Epsilon]=OptionValue[MinimalProbability];
pinit=OptionValue[InitialProbabilities];

l=Length[First[readcounts0]];
ttl=Plus@@#&/@readcounts0;
ps0=Position[Sign[ttl-OptionValue[GenotypingCoverage]],-1,{1},Heads->False];
readcounts=Delete[readcounts0,ps0];
psinsert=ps0-Range[0,Length[ps0]-1];

p=If[pinit==="Default",AlleleVectors[l],pinit];
bestcluster0=0;
Do[plog=Map[Log0[#,\[Epsilon]]&,p,{2}]//Transpose;
phred=readcounts.plog;
bestcluster=(Ordering[#,1]&/@phred)[[All,1]];
If[bestcluster0===bestcluster,Break[]];
p=N[#/Plus@@#]&/@Total[GatherBy[{readcounts,bestcluster}//Transpose,Last][[All,All,1]],{2}]//Sort;
If[OptionValue[PrintReports]===True,Print[p]];
bestcluster0=bestcluster,
{Max[2Length[readcounts],10]}];
{Insert[bestcluster,0,psinsert],p}
];


(*
Split2D splits biallelic read counts to 4 groups using the maximal spread angle. The forth group is the individuals with low (less than MinimalCoverage) read counts.
Input: (n x 2) matrix of read counts.
Output: {4 lists of positions of individuals in the 4 clusters}, the lists may be empty.
*)
Options[Split2D]={MinimalCoverage->6};
Split2D[readcounts_?MatrixQ,OptionsPattern[Split2D]]:=
Module[{mnrd,n,l,ttl,psok,psinsufficientreads,angles,anglesplus,ord,extra,mdl,anglessorted,g0,g12,clusters},

mnrd=OptionValue[MinimalCoverage];
n=Length[readcounts];
ttl=Total[readcounts,{2}];
(*ttl=readcounts[[All,1]]+readcounts[[All,2]]*)(*Plus@@#&/@readcounts*);

psok=Join@@Position[Sign[ttl-(mnrd-1)],1,{1},Heads->False];
l=Length[psok];
If[l===0,Return[{{},{},{},Range[n]}]];

psinsufficientreads=Complement[Range[n],psok];

angles=2./\[Pi] (ArcSin[N[readcounts[[psok,2]]]/Norm/@N[readcounts[[psok]]]]);

(*
3 "fake" points are added
*)
anglesplus=Join[angles,{-0.0000001,0.5,1.0000001}];
ord=Ordering[anglesplus];
extra=Ordering[ord,-3];
mdl=extra[[2]];
anglessorted=anglesplus[[ord]];
g0=Ordering[Differences[anglessorted[[1;;mdl]]],-1][[1]];
g12=Ordering[Differences[anglessorted[[mdl;;-1]]],-1][[1]]+mdl-1;
clusters={ord[[2;;g0]],DeleteCases[ord[[g0+1;;g12]],x_/;x>l],ord[[g12+1;;-2]]};

Append[psok[[#]]&/@clusters,psinsufficientreads]
];


(*
Split10D splits multiallelic read counts using Split2D on each allele count against the some of the rest allele counts.
Input: (n x d) matrix of allele count vectors.
Output: (n x 2) matrix representing initial genotypes, each in the form {j1,j2}, where for example {1,2} corresponds to '0/1'. 
{0,0} stands for low coverage individuals.
*)
Split10D[readcounts_?MatrixQ,optns:OptionsPattern[Split2D]]:=
Module[{mnrd,ll,trans,ttl,clusters,allelestoremove,allelestoremain,genotypesremaining,al,genotypes,ps0,genotypes0},

mnrd=OptionValue[MinimalCoverage];
ll=Dimensions[readcounts];

trans=Transpose[readcounts];
ttl=Total[trans];

(*
First cluster using Split2D - each allele vs the total of read counts for all other alleles
*)
clusters=Table[Split2D[Transpose[{ttl-rrr,rrr}],optns],{rrr,trans}];

(*
Find alleles to be removed - those that don't have multiple clusters
*)
allelestoremove=Join@@Position[RemoveAlleleQ/@clusters,True,{1},Heads->False];

(*
If all but one allele is to be removed, leave at least 2 alleles - those that have maximal number of reads across all samples
*)
If[Length[allelestoremove]>ll[[2]]-2,allelestoremove=Complement[allelestoremove,Ordering[Total/@trans,-2]]];

allelestoremain=Complement[Range[ll[[2]]],allelestoremove];

(*Print[allelestoremove];*)

(*
If there are alleles to be removed, then run the same function only on those remaining,
and then correct the allele numbers in the genotypes
*)
If[allelestoremove=!={},

genotypesremaining=Split10D[readcounts[[All,allelestoremain]],optns];
Return[If[#==={0,0},{0,0},allelestoremain[[#]]]&/@genotypesremaining]
];

(*
Collect the alleles from all clusters for each sample
*)
al={{},{1},{1,1},{}};

genotypes=
(Join@@#&/@(Table[ConvertClusterPositionsToGenotypes[clusters[[i]],al*allelestoremain[[i]]],{i,1,Length[allelestoremain]}]//Transpose));

ps0=Position[Sign[ttl-mnrd],-1,{1},Heads->False];

genotypes0=ReplacePart[genotypes,ps0->{0,0}];

(*
Some samples may get less than 2 or more than 2 alleles.
Those should be resolved - reduced to exactly 2 alleles.
*)
ResolveWrongGenotypes[genotypes0,readcounts]
];


(*
Input: the result of Split2D, i.e. 4 lists of positions.
If there is only one nonempty cluster and it is the 0/0 one than the function returns True, i.e. the second allele should be removed.
If the only cluster is 1/1 or there is more than one cluster, then the function returns False, i.e. no alleles should be removed.
*)
RemoveAlleleQ[genotype2Dclusters_List]:=Module[{nonempty},
nonempty=Join@@Position[genotype2Dclusters[[1;;3]],List[__],Heads->False];
(*Or[nonempty==={1},nonempty==={2}]*)
nonempty==={1}
]


(*
InitialSplit uses the split genotyping method to cluster read counts and returns a list of normalized vector probabilities for the cluster directions.
*)
InitialSplit[readcounts_,optns:OptionsPattern[Split2D]]:=Module[{d,grp0},
d=Length[readcounts[[1]]];

(* Biallelic case *)

If[d===2,
(
grp0=DeleteCases[Split2D[readcounts,optns][[1;;3]],{},{1}];
Return[N[#/Plus@@#]&/@((Total[Part[readcounts,#],{1}])&/@grp0)]
)
];

(* Multiallelic case *)

grp0=GatherBy[DeleteCases[Transpose[{Split10D[readcounts,optns],Range[Length[readcounts]]}],{{0,0},_},{1}],First][[All,All,2]];
N[#/Plus@@#]&/@Table[Total[Part[readcounts,rrr],{1}],{rrr,grp0}]
]


(*
Plot function. 
Input: {4 sets of pairs of reads}.
The sets: 
1)green: 0/0 genotype cluster,
2) blue: 0/1 genotype cluster,
3) red: 1/1 genotype cluster,
4) black: low number of reads.
The sets can be empty {}.
*)
PlotClusteredReadCounts2D[readcounts_List]:=Module[{x,colours,ps,mx,sz,markers},
colours={Darker[Green],Blue,Red,Black};
sz=Small;
markers={{"\[FilledCircle]",sz},{"\[FilledCircle]",sz},{"\[FilledCircle]",sz},{"\[CircleDot]",sz}};

ps=Join@@Position[readcounts,{},{1},Heads->False];
If[ps==={},x=readcounts,
x=Delete[readcounts,List/@ps];
colours=Delete[colours,List/@ps];
markers=Delete[markers,List/@ps]];

mx=Max[x];
ListPlot[x(*+(RandomReal[0.005mx {-1,1},{Length[#],2}]&/@x)*),
Background->White,
PlotRange-> mx{{-0.05`,1.05`},{-0.05`,1.05`}},
AxesOrigin->{0,0},
AspectRatio->1,
ImageSize->300,
PlotMarkers->markers,
PlotStyle->(colours)]
];


PlotClusteredReadCounts10D[genotypes_List,readcounts_?MatrixQ]:=Module[{dm,trans,ttl,reads2D,cnt,readsbygenotype,ps0,ps},
dm=Dimensions[readcounts];

ps0=Join@@Position[genotypes,{0,0},{1},Heads->False];
ps=Complement[Range[dm[[1]]],ps0];

trans=Transpose[readcounts];
ttl=Plus@@trans;

Table[
reads2D={ttl-trans[[j]],trans[[j]]}//Transpose;
cnt=Count[#,j]&/@genotypes[[ps]];
readsbygenotype=Pick[reads2D[[ps]],cnt,#]&/@{0,1,2};
(*ll=Length/@readsbygenotype;
af=(ll[[3]]+1/2 ll[[2]])/(Plus@@ll[[1;;3]])//N;*)
PlotClusteredReadCounts2D[Append[readsbygenotype,reads2D[[ps0]]]]
,{j,1,dm[[2]]}]
];


Options[Split2DPlot]={};Split2DPlot[readcounts_List,op:OptionsPattern[{Split2DPlot,Split2D}]]:=Module[{clst},
clst=Split2D[readcounts,FilterRules[{op},Options[Split2D]]];
PlotClusteredReadCounts2D[readcounts[[#]]&/@(clst)]
]


(*
Converts the list of clustered positions clusterpositions as in output of Split2D to a list of alleles based on genotypesofclusters
*)
ConvertClusterPositionsToGenotypes[clusterpositions_List,genotypesofclusters_List]:=Module[{ord,clusterlengths},
ord=Ordering[Flatten[clusterpositions]];
clusterlengths=Length/@clusterpositions;
(Join@@Table[genotypesofclusters[[j]],{j,1,Length[clusterpositions]},{clusterlengths[[j]]}])[[ord]]
];


(*
Input: a table of read counts, matrix (n x l).

Output: {a list of resolved alleles for each individual in the form {1,2} - matrix of integers (n x 2), 
a list of probability vectors for each cluster including empty clusters - matrix (l(l+1)/2 x l),
a list of phred probabilities for each individual - matrix (n x l(l+1)/2) with phred=0 for the allele called }

UseInitialSplit\[Rule]True tells the function to use the gap splitting first, and then to refine using statistical methods.
UseInitialSplit\[Rule]False tells the function to use the default initial probabilities {1,0}, {1/2,1/2}, {0,1}.
*)
Options[GenotypeReadCounts]={UseInitialSplit->True};
GenotypeReadCounts[readcounts_?MatrixQ,optns:OptionsPattern[{BinomialBestFit,GenotypeReadCounts,Split2D}]]:=Module[{ll,bbf,genotypes,init0,\[Epsilon],closest,clustn,p,plog,phred,scores,scores0},

ll=Dimensions[readcounts];
\[Epsilon]=OptionValue[MinimalProbability];

(*
If there is only one allele then the genotypes are trivial
*)
If[ll[[2]]===1,Return[{ConstantArray[{1,1},ll[[1]]],{{1}},ConstantArray[{0},ll[[1]]]}]];

(*
First split individuals to groups using nonstatistical split methods unless the option UseInitialSplit is set to False
*)
If[OptionValue[UseInitialSplit],
(init0=InitialSplit[readcounts,FilterRules[{optns},Options/@{Split2D}]];
If[init0==={},init0="Default"]),
init0="Default"
];

(*
Refine the clustering using multinomial likelihood based expectation-maximization algorithm
*)
bbf=BinomialBestFit[readcounts,InitialProbabilities->init0,FilterRules[{optns},Options/@{BinomialBestFit}]];

(*
Assign the genotypes to each cluster based on the closest allele vector
*)
closest=ClosestVectors[bbf[[2]]];
clustn=Prepend[closest[[2]],0][[bbf[[1]]+1]];
genotypes=AlleleCombinations[ll[[2]]][[clustn+1]];
p=closest[[1]];

(*
Calculate phred scores
*)
plog=Map[Log0[#,\[Epsilon]]&,p,{2}]//Transpose;
phred=readcounts.plog;
(* old
scores=Round[10(phred-(Min/@phred))];
*)

scores0=Round[10(phred-Extract[phred,Transpose[{Range[ll[[1]]],clustn+1-Sign[clustn]}]])];
scores=Map[If[#<0,1,#]&,scores0,{2}];

(*
Report {genotypes, probability vectors, phred scores}
*)
{genotypes,p,scores}
]


ResolveWrongGenotypes[genotypes_List,readcounts_?MatrixQ]:=Module[{k,lll,ps0,ps1,ps2,ps,suspectedgenotypes,picked,meanvector,ttt,newgenotypes},
k=readcounts[[1]]//Length;
lll=Length/@genotypes;
ps0=Join@@Position[lll,x_/;x===0,Heads->False];
ps1=Join@@Position[lll,x_/;x===1,Heads->False];
ps2=Join@@Position[lll,x_/;x>2,Heads->False];
ps=Join[ps0,ps1,ps2];

If[ps==={},Return[genotypes]];

suspectedgenotypes=Join[
If[ps0==={},{},Table[Sort/@Tuples[Range[k],2]//Union,{Length[ps0]}]],
Table[Sort[{rrr[[1]],#}]&/@Range[k],{rrr,genotypes[[ps1]]}],
Union[Subsets[#,{2}]]&/@genotypes[[ps2]]
];

newgenotypes=Table[
ttt=Table[picked=Pick[readcounts,(#===sss)&/@genotypes];

meanvector=If[picked==={},{ReplacePart[Table[0,{k}],(List/@sss)->1]},picked//N];
Min[VectorAngle[readcounts[[ps[[j]]]]//N,#]&/@meanvector]

,{sss,suspectedgenotypes[[j]]}];

suspectedgenotypes[[j,Ordering[ttt,1][[1]]]]
,{j,1,ps//Length}];

ReplacePart[genotypes,(#[[1]]->#[[2]])&/@Transpose[{ps,newgenotypes}]]
]


(*
Reorders the variant alleles and the corresponding read counts.
The reference allele is always left to be the first, the other alleles are sorted so that the alleles with the larger total number of reads for all samples come before those with smaller number of reads.
*)
ReorderAlleles[{vars_List,readcounts_List}]:=Module[{ord},
If[Length[vars]<3,Return[{vars,readcounts}]];
ord=Prepend[((-Total/@(Transpose[readcounts][[2;;-1]]))//Ordering)+1,1];
{vars[[ord]],readcounts[[All,ord]]}
];

ReorderAlleles[{coord_,vars_List,readcounts_List}]:=Prepend[ReorderAlleles[{vars,readcounts}],coord];



(*
Input: the result of Split2D, i.e. 4 lists of positions.
If there is only one nonempty cluster and it is the first 0/0 or 0/1 one than the function returns True, i.e. the second allele should be removed.
If the only cluster is 1/1 or there is more than one cluster, then the function returns False, i.e. no alleles should be removed.
*)
RemoveAlleleQ[genotype2Dclusters_List]:=Module[{nonempty},
nonempty=Join@@Position[genotype2Dclusters[[1;;3]],List[__],Heads->False];
Or[nonempty==={1},nonempty==={2}]
]


VariantPlot[x_List]:=Module[{l,sbs},
l=Length[x[[2]]];
If[l===2,Return[Show[Split2DPlot[x[[3]]],PlotLabel->Style[MakeCoordinateString[x[[1]]]<>"\n"<>x[[2,1]]<>"\[Rule]"x[[2,2]],{Larger}],AxesLabel->(Style[#,{Bold,Larger}]&/@x[[2]])]]];
sbs=Subsets[Range[l],{2}];
Show[VariantPlot[{x[[1]],x[[2,#]],x[[3,All,#]]}],PlotLabel->Style[MakeCoordinateString[x[[1]]]<>"\n"<>x[[2,1]]<>"\[Rule]"StringJoinWith[x[[2,2;;-1]],","],{Larger}]]&/@sbs
]


GenotypeToString[{-1,-1}]="./.";
GenotypeToString[x_List]:=ToString[x[[1]]]<>"/"<>ToString[x[[2]]]


ConvertVariantToVcfLine::usage=
"ConvertVariantToVcfLine[variant_List]
The function converts variant data for one variant to a line in vcf file.
Uses GenotypeReadCounts function to assign genotypes.
The function may reorder the alleles in the multiallelic case.
Input: {a list of coordinates of the variant, a list of allele sequences with the reference allele being first, a matrix of read counts of dimension number of individuals x number of alleles}.
Output: a list of strings ready to be written into the vcf table.
Last modification: 10 June 2016.";
Options[ConvertVariantToVcfLine]={};
ConvertVariantToVcfLine[variant_List,optns:OptionsPattern[{GenotypeReadCounts,ConvertVariantToVcfLine,BinomialBestFit,Split2D}]]:=Module[{l,afprecision,nalleles,multi,reord,gnt,allelesin,allelesout,alleleslist,an,afstring,ac,dp,infofield,smpl1,smpl2,smpl2ttl,smpl3min,smpl3,smpl,ord,ordord,score,res},

nalleles=Length[variant[[2]]];

If[Or[nalleles===1,variant[[2,2]]==="."],Return[{variant[[1,1;;2]],".",
variant[[2,1]],
".",
0,
"NoAlternativeAllele",
"AN="<>ToString[2 Length[variant[[3]]]]<>";DP="<>ToString[Plus@@variant[[3,All,1]]],
"GT:AD:DP:GQ:PL",
Table["0/0:"<>rrr<>":"<>rrr<>":0:0",{rrr,ToString/@variant[[3,All,1]]}]}//Flatten]];

multi=nalleles>2;

(* Twice the number of individuals *)
l=2Length[variant[[3]]];
afprecision=Ceiling[Log10[N[l]]]+1;

reord=If[multi,ReorderAlleles[variant],variant];
gnt=GenotypeReadCounts[reord[[3]],FilterRules[{optns},Options/@{BinomialBestFit,GenotypeReadCounts,Split2D}]];
allelesin=DeleteCases[Union@@(gnt[[1]]),0];
allelesout=Complement[Range[nalleles],allelesin];

If[And[multi,allelesout=!={}],
(
ord=Prepend[Join@@(DeleteCases[#,1]&/@{allelesin,allelesout}),1];
ordord=Ordering[ord];
If[ord=!=Range[nalleles],
(
reord[[2]]=reord[[2,ord]];
reord[[3]]=reord[[3,All,ord]];
gnt=GenotypeReadCounts[reord[[3]],FilterRules[{optns},Options/@{Split2D,GenotypeReadCounts}]];
allelesin=ordord[[allelesin]];
allelesout=ordord[[allelesout]]
)];
)
];

alleleslist=DeleteCases[Flatten[gnt[[1]]],0];
an=Length[alleleslist];
ac=ArrangeTallyList[(alleleslist//Tally),Range[2,nalleles]];
If[an>0,afstring=StringJoin[Riffle[(If[#===0,"0",ToString[NumberForm[#/an//N,{afprecision,afprecision},ExponentFunction->(Null&)]]]&/@ac),","]],afstring=StringJoin[Riffle[ConstantArray["0",Length[ac]],","]]];
dp=Total[reord[[3]],2];

infofield=StringJoin["AF=",
afstring,
";AN=",
ToString[an],
";AC=",
StringJoinWith[ac,","],
";DP=",
ToString[dp],
If[allelesout==={},"",";DM="<>StringJoinWith[reord[[2,allelesout]],","]]];

(*Genotypes*)
smpl1=GenotypeToString/@(gnt[[1]]-1);
(*Read counts*)
smpl2=(StringJoinWith[#,","])&/@reord[[3]];
(* Total read counts *)
smpl2ttl=(ToString)/@Total[reord[[3]],{2}];
(*Minimal phred score*)
smpl3min=(RankedMin[#,2])&/@gnt[[3]];
(*Phred scores*)
smpl3=(StringJoinWith[#,","])&/@gnt[[3]];
(*Final list for vcf file*)
smpl=StringJoinWith[#,":"]&/@Transpose[{smpl1,smpl2,smpl2ttl,ToString/@smpl3min,smpl3}];
score=Mean[smpl3min//N]//Round;

res={reord[[1,1;;2]],".",
reord[[2,1]],
StringJoinWith[reord[[2,2;;-1]],","],
score,
".",
infofield,
"GT:AD:DP:GQ:PL",
smpl}//Flatten;

Remove[l,afprecision,nalleles,multi,reord,gnt,allelesin,allelesout,alleleslist,an,afstring,ac,dp,infofield,smpl1,smpl2,smpl2ttl,smpl3min,smpl3,smpl,ord,ordord,score];

res
];


ConvertVcfLineToVariant[rrr_List]:={rrr[[1;;2]],Prepend[StringSplit[rrr[[5]],","],rrr[[4]]],AlleleCounts[rrr[[10;;-1]]]};

AlleleCounts["./."]:={0,0};
AlleleCounts[x_String]:=ToExpression/@StringSplit[StringSplit[x,":"][[2]],","];
AlleleCounts[xx_List]:=Map[FromDigits,StringSplit[StringSplit[xx,":"][[All,2]],","],{2}];


Options[RemoveDummyAlleles]={};
RemoveDummyAlleles[vcfline_List,optns:OptionsPattern[{Split2D,GenotypeReadCounts,ConvertVariantToVcfLine,RemoveDummyAlleles}]]:=Module[{fake,variantalleles,removepositions,var,newalleles,newallelesreduced,newvcfline,ac},
If[StringFreeQ[vcfline[[8]],";DM=",IgnoreCase->True],Return[vcfline]];
fake=StringSplit[StringCases[vcfline[[8]],Shortest["DM="~~yyy__~~(";"|EndOfString)]->yyy][[1]],","];

(* If the only dummy allele is the reference one then leave it as it is *)
If[fake==={vcfline[[4]]},Return[vcfline]];

variantalleles=StringSplit[vcfline[[5]],","];
removepositions=IntersectionPositionsSimple[variantalleles,fake][[All,1]];
newalleles=Prepend[Delete[variantalleles,List/@removepositions],vcfline[[4]]];
newallelesreduced=ReduceVariants[newalleles];

ac=AlleleCounts[vcfline[[10;;-1]]];

(* Exclude the dummy alleles from the variant *)
var={{vcfline[[1]],vcfline[[2]]+newallelesreduced[[2,1]],vcfline[[2]]+StringLength[newallelesreduced[[1,1]]]-1},newallelesreduced[[1]],Delete[#,List/@(removepositions+1)]&/@ac};
newvcfline=ConvertVariantToVcfLine[var,FilterRules[{optns},Options/@{ConvertVariantToVcfLine,Split2D,GenotypeReadCounts}]];

(* Now do it again *)

RemoveDummyAlleles[newvcfline,FilterRules[{optns},Options/@{ConvertVariantToVcfLine,Split2D,GenotypeReadCounts,RemoveDummyAlleles}]]
];


(*
Function that checks if the string starts with word "Error".
*)
ErrorCheck[x_]:=And[StringQ[x],StringMatchQ[x,"Error*"]]


(*
Design the right primer. Input: the reference sequence, the primer start position in the sequence, distancetonextvar - the maximal number of bases that the primer is allowed to have.

The function checks if the primer sequence is unique in the neighboring reference.
If it is, then the primer sequence is returned. If it is not, then another base is added on the right.
*)
Options[DesignRightPrimer]={RightPrimerLength->2,MaxShiftCheck->{-1,5}};
DesignRightPrimer[reference_String,startcoordinate_Integer,distancetonextvar_Integer:100,OptionsPattern[]]:=
Module[{pr,l,ref,uniq,prim,maxchecks},
maxchecks=OptionValue[MaxShiftCheck];
If[Not[ListQ[maxchecks]],maxchecks=maxchecks{-1,1}];
pr=Min[OptionValue[RightPrimerLength],distancetonextvar];
l=StringLength[reference];

uniq=False;
prim="Error: DesignRightPrimer";

Do[prim=StringTake[reference,{startcoordinate,startcoordinate+j-1}];
ref=StringTake[reference,{Max[startcoordinate+maxchecks[[1]],1],Min[startcoordinate+j-1+maxchecks[[2]](*Max[maxchecks[[2]],j]*),l]}];
If[StringCount[ref,prim,Overlaps->True]===1,
uniq=True;Break[]],
{j,pr,Min[l+1-startcoordinate,distancetonextvar]}];

prim
];


(*
Design the left primer. Input: the reference sequence, the primer start position in the sequence, variants - a set of regions in the sequence on the left from the startcoordinate where variation
is present. The format of each element in variants is {{p1,p2},{seq1,seq2,seq3}}, where p1,p2 are the positions in the sequence, seq1,seq2,seq3 are the variant sequences.
p1,p2>0 and p1,p2<=startcoordinate
*)
Options[DesignLeftPrimer]={LeftPrimerLength->2,MaxShiftCheck->5};
DesignLeftPrimer[reference_String,startcoordinate_Integer,variants_List:{},OptionsPattern[DesignLeftPrimer]]:=Module[{maxcheck,leftreference,startpr,pr,varseq,fullseq,checkseq,primers,uniq,l},
maxcheck=OptionValue[MaxShiftCheck];
leftreference=StringTake[reference,startcoordinate];

If[variants==={},
(
fullseq={leftreference};
),
(
varseq=Flatten[Outer[List,Sequence@@variants[[All,2]]],Length[variants]-1];
fullseq=StringReplacePart[leftreference,#,variants[[All,1]]]&/@varseq;
)
];
l=StringLength/@fullseq//Min;
startpr=Min[OptionValue[LeftPrimerLength],l];

uniq=False;

Do[primers=StringTake[fullseq,{-pr,-1}]//DeleteDuplicates;
checkseq=StringTake[#,{-Min[Max[2pr,pr+maxcheck],StringLength[#]],-1}]&/@fullseq;
If[Max[StringCount[checkseq,primers,Overlaps->True]]===1,
uniq=True;Break[]]
,{pr,startpr,l}];

primers
]


(*
PickAlleles filters "random" cases in the allele list for one sample. 
It takes a "Tally" list of alleles in the form {{A,na},{B,nb},{C,nc}},
calculates the total number of reads N=na+nb+nc, then picks only those alleles that the number of supporting reads is larger than 0.15N.
Then if the number of alleles is larger than 2 (ploidy) the function only keeps the 2 alleles with the largest number of supporting reads.
*)
Options[PickAlleles]={MinimalRatioNonreferenceReads->0.15,Ploidy->2,MinimalNumberNonreferenceReads->3};
PickAlleles[x_List,OptionsPattern[PickAlleles]]:=Module[{fthr,thr,pck,plo,mincover},
mincover=OptionValue[MinimalNumberNonreferenceReads];
fthr=OptionValue[MinimalRatioNonreferenceReads];
plo=OptionValue[Ploidy];
thr=Max[Total[x[[All,2]]]fthr,mincover];
pck=Pick[x,(#[[2]]>=thr)&/@x];
If[Length[pck]>plo,SortBy[pck,#[[2]]&][[-plo;;-1]],pck]
]


(*
ArrangeTallyList gives the allele counts in a certain order.
Input - "Tally" list of alleles with counts {{A,na},{B,nb},{C,nc}}, and a list of alleles in the required order e.g. {B,D,A,C}.
The function will output {nb,0,na,nc} in this case.
*)
ArrangeTallyList[x_List,varlist_List]:=Module[{f},
f[_]:=0;
(f[#[[1]]]=#[[2]])&/@x;
f/@varlist
]


(*
CountReadCases designs primers, finds variant alleles and counts the number of reads suppoting each allele in every sample.
coordinatesandbasecounts:{{chr,var start,end},{var min and max length}}:{{10,131634896,131634900},{3,6}};
sequences: list of reads by sample;
leftvariants: a list of variants on the left: {{{var1 start,end},{alleles1}},{{var2 start,end},{alleles2}},...}:{{{131634890,131634893},{"CAAT","CAT","CAAAT"}}};
rightvariantfirstcoord: the coordinate of the next variant on the right: 131634907.

Output: {{alleles},{{counts sample 1},{counts sample 2},...}}.
The first allele is always the reference allele, i.e. the reference sequence at {chr,var start,end}.

First the primers are of length 3.
If the number of cases matching the pattern is more than one in the reference
or in many reads, than the multiple cases are analyzed and the primers are prolonged accordingly.
If the right primer has to be extended, but cannot be due to the right limit, "Right primer cannot be prolonged" is returned.
*)
Options[CountReadCases]={};
CountReadCases[coordinatesandbasecounts_List,sequencescoordinatescigar_List,leftvariants_List:{},rightvariantfirstcoord_Integer:-1,optns:OptionsPattern[{CountReadCases,GetSequenceFromGenomeFasta,PickAlleles}]]:=Module[{readlength,chrcoord,basecounts,maxshifts,reference,MakeLocalCoord,localstart,leftvariantslocal,basesavailableontheright,rightprimerinput,leftprimerinput,rightprimer,leftprimer,primerpattern,ctch,refcases,seqcasestally,alleles,multiplecases,primerlengths,newprimers,allelesreffirst,counts,error, flank,iter,needtoextendprimers,sequences,shortreference,newrefcoord,newrefcoordlocal,PickAllelesLocal},

readlength=(StringLength/@Flatten[DeleteCases[sequencescoordinatescigar,{},{1}][[All,1,1]]]//Max);

chrcoord={coordinatesandbasecounts[[1]]}//Flatten;
basecounts=coordinatesandbasecounts[[2]];

If[2 (chrcoord[[3]]-chrcoord[[2]]+1)>readlength,Return["The region "<>MakeCoordinateString[chrcoord]<>" is too long!"]];

maxshifts=(basecounts-(chrcoord[[3]]-chrcoord[[2]]+1));

flank=Max[10,maxshifts+5];

reference=GetSequenceFromGenomeFasta[chrcoord+{0,-readlength,readlength},(*BUG here?*)FilterRules[{optns},Options[GetSequenceFromGenomeFasta]]];
localstart=chrcoord[[2]]-readlength-1;
MakeLocalCoord[x_]=x-localstart;
leftvariantslocal={MakeLocalCoord/@#[[1]],#[[2]]}&/@leftvariants;

rightprimerinput={reference,
MakeLocalCoord[chrcoord[[3]]]+1,
MaxShiftCheck->{Min[-2,maxshifts[[1]]],Max[12,maxshifts[[2]]]},RightPrimerLength->4};
rightprimer=DesignRightPrimer[Sequence@@rightprimerinput];

leftprimerinput={reference,
MakeLocalCoord[chrcoord[[2]]]-1,
Select[leftvariantslocal,#[[1,1]]>0&],
MaxShiftCheck->Max[12,Abs[maxshifts[[1]]]],LeftPrimerLength->4};
leftprimer=DesignLeftPrimer[Sequence@@leftprimerinput];

primerlengths=(StringLength/@{leftprimer[[1]],rightprimer});

iter=Max[primerlengths]+20;

sequences=CutReadSlice[sequencescoordinatescigar,chrcoord[[2;;3]],readlength,FlankingBases->(primerlengths+(flank))];

newrefcoord={chrcoord[[2]]-primerlengths[[1]]-flank,chrcoord[[3]]+primerlengths[[2]]+flank};
newrefcoordlocal=MakeLocalCoord/@newrefcoord;
If[And[newrefcoordlocal[[1]]>0,newrefcoordlocal[[2]]<=StringLength[reference]],
shortreference=StringTake[reference,newrefcoordlocal],
shortreference=GetSequenceFromGenomeFasta[{chrcoord[[1]],newrefcoord},FilterRules[{optns},Options[GetSequenceFromGenomeFasta]]]];
(*shortreference=StringTake[reference,MakeLocalCoord/@{chrcoord[[2]]-primerlengths[[1]]-flank,chrcoord[[3]]+primerlengths[[2]]+flank}];*)

localstart=newrefcoord[[1]]-1;
MakeLocalCoord[x_]=x-localstart;
leftvariantslocal={MakeLocalCoord/@#[[1]],#[[2]]}&/@leftvariants;

basesavailableontheright=If[rightvariantfirstcoord<0,100,rightvariantfirstcoord-chrcoord[[3]]-1];

rightprimerinput={shortreference,
MakeLocalCoord[chrcoord[[3]]]+1,
basesavailableontheright,
MaxShiftCheck->maxshifts};
rightprimer=DesignRightPrimer[Sequence@@rightprimerinput];

leftprimerinput={shortreference,
MakeLocalCoord[chrcoord[[2]]]-1,
Select[leftvariantslocal,#[[1,1]]>0&],
MaxShiftCheck->(basecounts-(chrcoord[[3]]-chrcoord[[2]]+1))[[2]]};
leftprimer=DesignLeftPrimer[Sequence@@leftprimerinput];


error="Primers cannot be designed after "<>ToString[iter]<>" iterations";

Do[If[ErrorCheck[rightprimer],error=rightprimer;Break[]];
primerpattern=(StringExpression[#,yyy:Repeated[LetterCharacter,basecounts],rightprimer]->yyy)&/@leftprimer;
(*Print["pattern: ",primerpattern];*)

ctch=Catch[
refcases=StringCases[shortreference,primerpattern,Overlaps->All];
(*Print["refcases: ",refcases];*)
If[refcases==={},PrintError["CountReadCases:\nThe reference sequence doesn't have the pattern!\n"<>StringJoinWith[{shortreference,StringJoinWith[#,","]&/@coordinatesandbasecounts,primerpattern},"\n"]<>"\nABORTING!"];Abort[]];
If[Length[refcases]>1,Throw[{refcases}]];

seqcasestally=Tally[#]&/@(DeleteCases[StringCases[#,primerpattern,Overlaps->All]&/@sequences,{},{2}]);

PickAllelesLocal[x_]=PickAlleles[x,FilterRules[{optns},Options[PickAlleles]]];

alleles=Union@@((PickAllelesLocal/@seqcasestally)[[All,All,1]]);
(*Print["alleles: ",alleles];*)
If[Max[Length/@alleles]>1,Throw[alleles],(error="OK";Break[])];
];

primerlengths=(StringLength/@{leftprimer[[1]],rightprimer});
multiplecases=(*SubSequence/@*)Select[ctch,Length[#]>1&];
needtoextendprimers={Or@@(LeftPrimerNeedsExtension[leftprimer,#]&/@multiplecases),Or@@(RightPrimerNeedsExtension[rightprimer,#]&/@multiplecases)};
(*Print["extend primers?  ",needtoextendprimers];*)

If[SameQ@@needtoextendprimers,primerlengths+={1,1},
(If[needtoextendprimers[[1]],
primerlengths+={1,0}];

If[needtoextendprimers[[2]],
If[primerlengths[[2]]<basesavailableontheright,primerlengths+={0,1},error="Right primer cannot be prolonged";Break[]]])
];


newprimers={DesignLeftPrimer[Sequence@@leftprimerinput,LeftPrimerLength->primerlengths[[1]]],DesignRightPrimer[Sequence@@rightprimerinput,RightPrimerLength->primerlengths[[2]]]};
If[newprimers==={leftprimer,rightprimer},error="New primers identical to old";Break[]];
{leftprimer,rightprimer}=newprimers;
,{iter}];

If[(*!ListQ[alleles]*)error=!="OK",Return[error]];

allelesreffirst=Prepend[DeleteCases[alleles,refcases],refcases];
counts=ArrangeTallyList[#,allelesreffirst]&/@seqcasestally;
{Join@@allelesreffirst,counts}
];





(*
SubSequence[x,y] checks if y is a substring of x.
Output can be: "Identical","No","Left","LeftMiddle","LeftMiddleRight","LeftRight","MiddleRight","Right".

SubSequence[x_List] checks if the longest subsequence contains the second longest as a substring.
*)
SubSequence[x_String,y_String]:=Module[{ps,l},
If[x===y,Return["Identical"]];
ps=StringPosition[x,y,Overlaps->All];
If[ps==={},Return["No"]];
l=StringLength[x];
If[MemberQ[ps,{1,_}],"Left",""]<>If[MemberQ[ps,{m_/;m>1,n_/;n<l}],"Middle",""]<>If[MemberQ[ps,{_,l}],"Right",""]
];

SubSequence[x_List]:=Module[{longestpair},
If[Length[x]<=1,Return["Less than 2 strings in the list!"]];
longestpair=SortBy[x(*DeleteDuplicates[x]*),StringLength[#]&][[-1;;-2;;-1]];
SubSequence@@longestpair
];


RightPrimerNeedsExtension[primer_String,alleles_List]:=Or@@((Length[#]>1)&/@StringPosition[(#1<>primer&)/@alleles,primer])


LeftPrimerNeedsExtension[primers_List,alleles_List]:=Or@@((Length[#]>1)&/@StringPosition[Outer[StringJoin,primers,alleles]//Flatten,primers])


(*
ReduceVariants takes a list of sequences and chops away any characters at the end and at the beginning of the sequences that are the same for all sequences.
Leaves at least one character in any sequence!
*)

ReduceVariants[x_List]:=Module[{res,left,right,l},
res=x;
left=0;
right=0;
l=StringLength[x]//Min;

Do[If[Min[StringLength[res]]<2,Break[]];
If[Not[SameQ@@(StringTake[res,-1])],Break[]];
right++;res=StringDrop[res,-1];,{l}];

Do[If[Min[StringLength[res]]<2,Break[]];
If[Not[SameQ@@(StringTake[res,1])],Break[]];
left++;res=StringDrop[res,1],{l}];

{res,{left,right}}
];


(*
The input: sortedintegerlist is a sorted list of integers, repeats are allowed.
y={y1,y2} is a list of two integer numbers.
Output: {n1,n2}={n1 is the position of the first integer in sortedintegerlist which is \[GreaterEqual] y1,n2 is the position of the last integer in sortedintegerlist which is \[LessEqual] y2}.
If there are no integers x in the list that are y1\[LessEqual]x\[LessEqual]y2, then {n1,n2} with n1>n2 is returned.
Then sortedintegerlist[[n1;;n2]] is the list of all integers that are y1\[LessEqual]x\[LessEqual]y2.

BoundaryPositionsSimple is a simple straightforward function (changed on 2015feb19),
BoundaryPositions uses a trick to make it run faster, especially when y1 and y2 are quite close to each other.
*)
BoundaryPositionsSimple[sortedintegerlist_List,y_List]:=Ordering[Ordering[Join[{y[[1]]},sortedintegerlist,{y[[2]]}]]][[{1,-1}]]-{0,2};

BoundaryPositions[sortedintegerlist_List,y_List,step_Integer:0]:=Module[{l,indxpos,indx,ps,pos,st},
l=Length[sortedintegerlist];
If[l<10000,Return[BoundaryPositionsSimple[sortedintegerlist,y]]];
If[Or[sortedintegerlist[[1]]>y[[2]],sortedintegerlist[[-1]]<y[[1]]],Return[{1,0}]];
st=If[step===0,Sqrt[l]//Round,step];

indxpos=Append[Range[1,l-(st/2//Round),st],l];
indx=sortedintegerlist[[indxpos]];
ps=BoundaryPositionsSimple[indx,y];
pos=indxpos[[{Max[ps[[1]]-1,1],Min[ps[[2]]+1,Length[indx]]}]];
pos[[1]]-1+BoundaryPositionsSimple[sortedintegerlist[[Range@@pos]],y]
];


SelectSequences[seqcoord_List,coords_List,readlength_Integer:100]:=Table[cas[[Range@@BoundaryPositions[cas[[All,2]],{coords[[2]]-readlength,coords[[1]]}],1]],{cas,seqcoord}];


CountReadCasesTop[coordinatesandbasecounts_List,sequences_List,leftvariants_List:{},rightvariantfirstcoord_Integer:-1,optns:OptionsPattern[{CountReadCases,GetSequenceFromGenomeFasta,PickAlleles}]]:=Module[{firstcount,varsreduced,newcoords,newbasecounts,secondcount},

firstcount=CountReadCases[coordinatesandbasecounts,sequences,leftvariants,rightvariantfirstcoord,optns];
If[StringQ[firstcount],Return[firstcount]];
If[Length[firstcount[[1]]]<2,Return["No variants"]];
varsreduced=ReduceVariants[firstcount[[1]]];
If[varsreduced[[2]]==={0,0},Return[Prepend[firstcount,Flatten[coordinatesandbasecounts[[1]]]]]];
newcoords=Flatten[coordinatesandbasecounts[[1]]]+{0,varsreduced[[2,1]],-varsreduced[[2,2]]};
newbasecounts={Min[#],Max[#]}&@(StringLength/@varsreduced[[1]]);
(*Print["=================\n",{newcoords,newbasecounts},"\n================="];*)
secondcount=CountReadCases[{newcoords,newbasecounts},sequences,leftvariants,rightvariantfirstcoord,optns];
If[StringQ[secondcount],secondcount,Prepend[secondcount,newcoords]]
]


(* 
Join two (or more) subsequent regions to one. 
*)

CombineTwoRegionsWithCounts[regionsall_List]:=Module[{regions,rg,ct},
regions=DeleteCases[regionsall,{},{1}];
rg={Min[regions[[All,1]]],Max[regions[[All,1]]]};
ct=rg[[2]]-rg[[1]]+1+Sum[regions[[j,2]]-regions[[j,1,2]]+regions[[j,1,1]]-1,{j,1,Length[regions]}];
{rg,{Max[ct[[1]],1],ct[[2]]}}
];

(* 
Joins all subsequent regions with distance between them less or equal to OptionValue[CombineDistance].
Input is in a form of list of pairs of numbers.
*)
Options[CombineRegionsWithCounts]={ApplySort->True,CombineDistance->1};
CombineRegionsWithCounts[regions_List,OptionsPattern[CombineRegionsWithCounts]]:=Module[{xxx,res,crnt,xxj,dist},

If[regions==={},Return[{}]];

xxx=If[OptionValue[ApplySort],SortBy[regions,#[[1,{1,-1}]]&],regions];
dist=OptionValue[CombineDistance];
res={};crnt=xxx[[1]];
Do[xxj=xxx[[j]];
If[xxj[[1,1]]-crnt[[1,-1]]<=dist,
crnt=CombineTwoRegionsWithCounts[{crnt,xxj}],
(AppendTo[res,crnt];crnt=xxj)],{j,2,Length[xxx]}];
AppendTo[res,crnt]
];



Options[FindAllelesAndCountReads]={AnticipatedReadLength->300};
FindAllelesAndCountReads[bamfiles_,region_List,optns:OptionsPattern[{FindAllelesAndCountReads,ScanForVariantCandidates,GetReadsFromBamFiles}]]:=Module[{flbam,chr,suspectedvariants,l,readlength,actualreadlength,seqcoord,res,reslength,previousvars,varj,seqj,countsj,problems,tm,logs},

Switch[bamfiles,_List,flbam=bamfiles,_String,flbam=ReadList["!ls "<>bamfiles,String],_,Return["The bam files are ill-defined"]];

problems={};

chr=region[[1]];

readlength=OptionValue[AnticipatedReadLength];

(*Print["Scanning finished: ",*)suspectedvariants=CombineRegionsWithCounts[ScanForVariantCandidates[flbam,region,FilterRules[{optns},Options[ScanForVariantCandidates]]]];(*//AbsoluteTiming,"\n",suspectedvariants//Length," possible variants."];*)

If[suspectedvariants==={},Return[{{},{}}]];

l=Length[suspectedvariants];

Label["again"];

(*Print["Preparing sequences:\t",*)seqcoord=GetReadsFromBamFiles[flbam,{chr,CombineRegions[suspectedvariants[[All,1]],CombineDistance->2readlength](*suspectedvariants[[1,1,1]],suspectedvariants[[-1,1,2]]*)},
FilterRules[{optns},Options[GetReadsFromBamFiles]]];
(*//AbsoluteTiming];*)

actualreadlength=(StringLength[Flatten[seqcoord[[All,1;;-1;;1000,1]]]]//Max);
If[actualreadlength>1.2readlength,readlength=actualreadlength;Goto["again"]];

logs=OptionValue[LogStream];

If[logs=!=False,WriteString[logs,tm=DateString[],"\tStarted evaluation of variant sites.\n"]];

(*Print["Calculations:\t",*)
(
res={};
previousvars={};
Do[
(*Print[j,"\t",suspectedvariants[[j]]];*)

reslength=Length[res];

Catch[
If[previousvars==={},varj=suspectedvariants[[j]],varj=CombineTwoRegionsWithCounts[{previousvars,suspectedvariants[[j]]}](*;Print["--->",j,"\t",varj]*)];

(*Print[varj,"\t",*)
countsj=CountReadCasesTop[{{chr,varj[[1]]},varj[[2]]},seqcoord,{#[[1,2;;3]],#[[2]]}&/@If[reslength>5,res[[-5;;-1]],res],If[j===l,-1,suspectedvariants[[j+1,1,1]]],FilterRules[{optns},Options/@{CountReadCases,PickAlleles,GetSequenceFromGenomeFasta}]];(*//AbsoluteTiming];*)

If[countsj==="No variants",previousvars={};Throw[1]];
If[countsj==="Right primer cannot be prolonged",previousvars=varj;Throw[1]];
If[StringQ[countsj],(*PrintError["Something is wrong!\n",varj,"\n",countsj];*)
AppendTo[problems,
{{{chr,varj[[1]]},varj[[2]]},countsj,{#[[1,2;;3]],#[[2]]}&/@If[reslength>5,res[[-5;;-1]],res],If[j===l,-1,suspectedvariants[[j+1,1,1]]]}
(*Insert[varj,chr,{1,1}]*)];
previousvars={};Throw[1]];

(*Print["result:",Style[countsj[[1;;2]],Bold],"\n",VariantPlot[countsj]];*)
AppendTo[res,countsj];
previousvars={};
Throw[0]
];
(*Print[If[StringQ[countsj],countsj,countsj[[1;;2]]]]*)
,{j,1,l}];
)

If[logs=!=False,WriteString[logs,DateString[],"\tFinished evaluation of variant sites.\t",NumberForm[-DateDifference[tm,"Second"][[1]],{10,1},ExponentFunction->(Null&)]," seconds.\n"]];

Remove[flbam,chr,suspectedvariants,l,readlength,actualreadlength,seqcoord,reslength,previousvars,varj,seqj,countsj,tm,logs];

(*If[problems=!={},PrintError["problems:\n",problems]];*)
{res,problems}
];


ScanForVariantCandidates::usage="ScanForVariantCandidates[bamfiles_, inputregion_, FastaFileName->GenomeFastaFile, MinimalCoverage\[Rule]10, MinimalRatioNonreferenceReads\[Rule]0.2, MinimalNumberNonreferenceReads\[Rule]3, SamtoolsFlagFilter\[Rule]1796, MinimalBaseSequencingScore\[Rule]13, MinimalReadMappingScore\[Rule]30, SaveCoverage\[Rule]False]
The function runs samtools mpileup, loads the output as a table, identifies the samples and positions where there is some variation, i.e. read number >= MinimalCoverage and number of nonreference reads >= MinimalNumberNonreferenceReads and the ratio of nonreference reads > MinimalRatioNonreferenceReads for at least one sample. Produces the coordinates of identified variants, the min and max estimates of variant base length and the maximal non-reference read ratio.
Input: bamfiles is a list of bam files (one individual per each file) or a string like \"*.bam\" or \"D????.bam\" that is converted to a list of files using unix command 'ls'. 
inputregion specifies the region to scan for variant candidates in. It can be in the form of a coordinate string like \"chr1:10000000-10000300\", or coordinate list like {chr1,10000000,10000300}, or for multiple regions to be scanned in one go like {chr1,{{10000000,10000300},{20000000,20000300}...}}.
Output: A list of variant candidates, each in the following format: {{2784882,2784886}, {1,5}, 0.224}, where the first two numbers are the coordinates of the affected site on the reference genome, the second two numbers are the estimate for the min and max size of the allele sequences, the last number is the maximal ratio of nonreference reads per individual. 
Option FastaFileName specifies the fasta file with the DNA sequence, must be the same as the one used for read alignment.
Option MinimalCoverage specifies the minimal (among the individuals) read coverage for the site to be scanned.
Option MinimalRatioNonreferenceReads gives the ratio of non-reference reads to total reads that at least one individual must exceed for the site to be taken into account.
Option MinimalNumberNonreferenceReads gives the number of non-reference reads that at least one individual must exceed for the site to be taken into account.
Option SamtoolsFlagFilter->1796 specifies the filter flags --ff in \'samtools mpileup\' command. The default filters out all reads for which one of the following flags is set:\[IndentingNewLine]0x4 (unmapped), 0x100 (not primary), 0x200 (failure), 0x400 (duplicate).
Option MinimalBaseSequencingScore\[Rule]13 specifies the minimal base sequencing quality score to be taken into account in mpileup. The default 13 corresponds to 10^(-1.3)=0.05 chance that the base was called in a wrong way.
Option MinimalReadMappingScore\[Rule]30 specifies the minimal alignment score for the read to be included in mpileup. Score 60 is the maximum in the BWA read alignment output, score 0 means that the read maps equally well to more than one location.
Last modification: 21 Nov 2016.";
Options[ScanForVariantCandidates]={
FastaFileName->GenomeFastaFile,
MinimalCoverage->6,
MinimalRatioNonreferenceReads->0.2,
MinimalNumberNonreferenceReads->3,
MaxIndelSize->30,
SamtoolsFlagFilter->"1796",
MinimalBaseSequencingScore->13,
MinimalReadMappingScore->30,
SaveCoverage->False,
LogStream->False
};
ScanForVariantCandidates[bamfiles_,inputregion_,optns:OptionsPattern[{ScanForVariantCandidates}]]:=Module[{cov,thr,genomefasta,maxindellength,cmd,awkcmd,cutcmd,flbam,l,region,types,mpileup,coverage,highcovpos,highcovmpileup,strcount,posabovethreshold,varpos,deletioninsertioncases,varlength,sublength,un,selectpositions,multiregioncalculation,regionbedfile,maxratios,savecoverage,teecmd,coveragefile,logs,tm,indelpatterns,ptrn,bamlistfile,nonrefmin,posaboveminimum,nonrefcount,maxcounts,result},
cov=OptionValue[MinimalCoverage];
thr=OptionValue[MinimalRatioNonreferenceReads];
nonrefmin=OptionValue[MinimalNumberNonreferenceReads];
maxindellength=OptionValue[MaxIndelSize];
genomefasta= OptionValue[FastaFileName];
CheckFileExistence[genomefasta];
logs=OptionValue[LogStream];

If[logs=!=False,WriteString[logs,tm=DateString[],"\tStarted the initial variant scan.\n"]];

Switch[OptionValue[SaveCoverage],
True,savecoverage=True;coveragefile=FileNameJoin[{TidyVarTmpDirectory,"coverage.txt"}],
False,savecoverage=False,
_String,savecoverage=True;coveragefile=OptionValue[SaveCoverage],
_,PrintError["Wrong value of Option SaveCoverage: "<>ToString[OptionValue[SaveCoverage]]];Abort[]];

multiregioncalculation=And[ListQ[inputregion],MatrixQ[inputregion[[2]]]];

If[multiregioncalculation,
(regionbedfile=FileNameJoin[{TidyVarTmpDirectory,"region_temp_"<>FromCharacterCode[RandomInteger[{97,122},10]]<>".bed"}];
WriteString[regionbedfile,
StringJoinWith[StringJoinWith[{inputregion[[1]],#+{-1,0}},"\t"]&/@inputregion[[2]],"\n"]
];
Close[regionbedfile])
];

Switch[bamfiles,_List,flbam=bamfiles,_String,flbam=ReadList["!ls "<>bamfiles,String],_,PrintError["The bam files are ill-defined.\nAborting!"];
Abort[]];

(bamlistfile=FileNameJoin[{TidyVarTmpDirectory,"bam_temp_"<>FromCharacterCode[RandomInteger[{97,122},10]]<>".txt"}];
WriteString[bamlistfile,
StringJoinWith[flbam,"\n"],"\n"
];
Close[bamlistfile]);

(* Get the pileup using samtools mpileup *)

l=flbam//Length;

region={inputregion[[1]],{Min[#],Max[#]}&@inputregion[[2;;]]};

(* The awk command checks that the coverage of at least one sample is above the threshold *)

(*awkcmd="awk '"<>
"BEGIN {FS=\"\\t\"; OFS=\"\\t\"} "<>
StringDrop[StringJoin[("$"<>ToString[#]<>">="<>ToString[cov]<>"||")&/@(1+3Range[l])],-2]<>" {print $1,$2,$3"<>StringJoin[(",$"<>ToString[#])&/@Riffle[(1+3Range[l]),(2+3Range[l])]]<>" }'"; *)

awkcmd="awk 'BEGIN {FS=\"\\t\"} { for (i = 1; i <= "<>ToString[l]<>"; ++i) { if ($(1+3*i)>="<>ToString[cov]<>") { print $0; break } }  }'";

(* The cut command removes  *) 

 cutcmd="cut --complement -f"<>StringJoinWith[(3+3Range[l]),","]<>" -";

If[savecoverage,teecmd=" | tee /dev/fd/3 | cut --complement -f "<>StringJoinWith[(3+2Range[0,l]),","]<>" >> "<>coveragefile<>" ) 3>&1"];

(*sedcmd="sed 's/\\(\\,\\|\\.\\)//g'";*)

cmd={"(",(* "samtools mpileup -BQ0 -d 10000 -A -f" *)
SamtoolsPath<>"samtools mpileup",
"--ff",OptionValue[SamtoolsFlagFilter],
"-B -A",
"-Q",OptionValue[MinimalBaseSequencingScore],
If[OptionValue[MinimalReadMappingScore]===0,"",{"-q",OptionValue[MinimalReadMappingScore]}],
(*"-d 1000",*)
"-f" ,genomefasta,
 "-r",(region//MakeCoordinateString),
If[multiregioncalculation,{"-l",regionbedfile},""],
(*flbam*)
"-b",bamlistfile,
"2> /dev/null",
"|",awkcmd,
"|",cutcmd
,If[savecoverage,teecmd,")"]}//StringJoinWith;

types=Flatten[{Word,Number,Word,Table[{Number,Word},{l}]}];
(*Return[RunExternal[cmd,String]];*)
mpileup=RunExternal[cmd,types,WordSeparators->"\t",NullWords->True];
(*mpileup//Dimensions)//AbsoluteTiming//Print;*)
If[multiregioncalculation,DeleteFile[regionbedfile]];
DeleteFile[bamlistfile];

(* The coverage columns are flattened to one long list *)
coverage=Join@@mpileup[[All,4;;-1;;2]];
highcovpos=Join@@Position[Sign[coverage-(cov-1)],1,{1},Heads->False];
highcovmpileup=(Join@@mpileup[[All,5;;-1;;2]])[[highcovpos]];

indelpatterns=
("+"|"-"~~ToString[#]~~Repeated["A"|"C"|"G"|"T",#]&/@Range[10,1,-1]);
ptrn=Join[indelpatterns,{"A"|"C"|"G"|"T"}];
strcount=StringCount[highcovmpileup,ptrn,Overlaps->False,IgnoreCase->True];

(*strcount=StringCount[highcovmpileup,LetterCharacter(*{"+"~~DigitCharacter..~~LetterCharacter..,"-"~~DigitCharacter..~~LetterCharacter..,LetterCharacter}*)
(* Not really right *),Overlaps\[Rule]False];*)

posaboveminimum=Join@@Position[Sign[strcount-(nonrefmin-1)],1,{1}];
posabovethreshold=posaboveminimum[[Join@@Position[Sign[(strcount[[posaboveminimum]]//N)/(coverage[[highcovpos[[posaboveminimum]]]]//N)-thr],1,{1}]]];
(*posabovethreshold=Join@@Position[Sign[(strcount//N)/(coverage[[highcovpos]]//N)-thr],1,{1}];*)

(*If[posabovethreshold==={},Return[{}]];*)

If[posabovethreshold=!={},

(* Looks for deletions and insertions and gives the number of bases that may have been deleted and inserted *)
deletioninsertioncases=If[Length[#]<nonrefmin,{0,0},{Max[Min[Min[#],0],-maxindellength],Min[Max[Max[#],0],maxindellength]}(*Sort[Append[#,0]][[{1,-1}]]*)]&/@Map[ToExpression,StringCases[highcovmpileup[[posabovethreshold]],("+"|"-")~~DigitCharacter..(*yyy:(("+"|"-")~~DigitCharacter..)~~LetterCharacter..\[Rule]yyy*)],{2}];

(* Unflattens the long list, counts the position, length and possible number of bases for each variant *)
{varpos,varlength,sublength,maxratios,maxcounts}=Transpose[{#[[1,1]],un=(Union@@(#[[All,2]]))[[{1,-1}]];-un[[1]],un-un[[1]]+1,Max[#[[All,3]]],Max[#[[All,4]]]}&/@GatherBy[Transpose[{Quotient[highcovpos[[posabovethreshold]],l,1]+1,deletioninsertioncases,((nonrefcount=strcount[[posabovethreshold]])//N)/(coverage[[highcovpos[[posabovethreshold]]]]//N),nonrefcount}],First]
];

result={Transpose[{mpileup[[varpos,2]],mpileup[[varpos,2]]+varlength}],sublength,maxratios,maxcounts}//Transpose;
,
result={}
];

If[logs=!=False,WriteString[logs,DateString[],"\tFinished the initial variant scan. Found ",Length[result]," potential variant locations.\t",NumberForm[-DateDifference[tm,"Second"][[1]],{10,1},ExponentFunction->(Null&)]," seconds.\n"]];

Remove[cov,thr,genomefasta,maxindellength,cmd,awkcmd,cutcmd,flbam,l,region,types,mpileup,coverage,highcovpos,highcovmpileup,strcount,posabovethreshold,varpos,deletioninsertioncases,varlength,sublength,un,selectpositions,multiregioncalculation,regionbedfile,maxratios,savecoverage,teecmd,coveragefile,logs,tm,indelpatterns,ptrn,bamlistfile,nonrefmin,posaboveminimum,nonrefcount,maxcounts];

result
];



GetReadsFromBamFiles::usage="GetReadsFromBamFiles[bamfiles_, region_, SamtoolsFlagFilter\[Rule]\"0x704\", MinimalReadMappingScore\[Rule]30, LogStream\[Rule]False]
The function runs \'samtools view\' for each bam file in bamfiles (must be sorted and indexed) and outputs 3 sam format columns: the read sequence, the coordinate (no chromosome) and the CIGAR string for each read in the specified region.
Input: bamfiles is a list of bam files (one individual per each file) or a string like \"*.bam\" that is converted to a list of files using unix command 'ls'.
inputregion specifies the region to scan for variant candidates in. It can be in the form of a coordinate string like \"chr1:10000000-10000300\", or coordinate list like {chr1,10000000,10000300}, or for multiple regions to be scanned in one go like {chr1,{{10000000,10000300},{20000000,20000300}...}}.
Output: a list of matrices, one matrix per bam file. Each matrix has 3 columns: the read sequence, the left read coordinate (no chromosome) and the CIGAR string.
Option SamtoolsFlagFilter->\"0x704\" specifies the filter flags in samtools view command. The default filters out all reads for which one of the following flags is set:\[IndentingNewLine]0x4 (unmapped), 0x100 (not primary), 0x200 (failure), 0x400 (duplicate).
Last modification: 22 June 2017.";
Options[GetReadsFromBamFiles]={SamtoolsFlagFilter->"1796",MinimalReadMappingScore->30,LogStream->False};
GetReadsFromBamFiles[bamfiles_,inputregion_,OptionsPattern[GetReadsFromBamFiles]]:=Module[{cmd,flbam,types,region,multiregioncalculation,logs,tm,regionbedfile,result},

Switch[bamfiles,_List,flbam=bamfiles,_String,flbam=ReadList["!ls "<>bamfiles,String],_,Return["The bam files are ill-defined"]];

logs=OptionValue[LogStream];

If[logs=!=False,WriteString[logs,tm=DateString[],"\tStarted to prepare the reads.\n"]];

multiregioncalculation=And[ListQ[inputregion],MatrixQ[inputregion[[2]]]];

If[multiregioncalculation,
(regionbedfile=FileNameJoin[{TidyVarTmpDirectory,"region_temp_"<>FromCharacterCode[RandomInteger[{97,122},10]]<>".bed"}];
WriteString[regionbedfile,
StringJoinWith[StringJoinWith[{inputregion[[1]],#+{-1,0}},"\t"]&/@inputregion[[2]],"\n"]
];
Close[regionbedfile])
];

region={inputregion[[1]],{Min[#],Max[#]}&@inputregion[[2;;]]}//MakeCoordinateString;

(*
region=If[multiregioncalculation,
StringJoinWith[MakeCoordinateString[{inputregion[[1]],#}]&/@inputregion[[2]]],
inputregion//MakeCoordinateString];
*)

types={Word,Number,Word};

result=Table[
(*
"-F 0x704" filters out all the sequences for which one of the following flags is set:
0x4 (unmapped),0x100 (not primary),0x200 (failure),0x400 (duplicate)
*)
cmd={SamtoolsPath<>"samtools view", 
If[OptionValue[SamtoolsFlagFilter]===0,"",{"-F",OptionValue[SamtoolsFlagFilter]}],
If[OptionValue[MinimalReadMappingScore]===0,"",{"-q",OptionValue[MinimalReadMappingScore]}],
rr,region,
If[multiregioncalculation,{"-L",regionbedfile},""],
"|","awk '{print $10,$4,$6}'"}//StringJoinWith;

RunExternal[cmd,types],
{rr,flbam}];

DeleteFile[regionbedfile];

If[logs=!=False,WriteString[logs,DateString[],"\tFinished to prepare the reads.\t",NumberForm[-DateDifference[tm,"Second"][[1]],{10,1},ExponentFunction->(Null&)]," seconds.\n"]];

Remove[cmd,flbam,types,region,multiregioncalculation,logs,tm,regionbedfile];

result
];


GetGenomicSpreadOfRead[x_String]:=GetGenomicSpreadOfRead[x]=CigarLength[x];
CountDeletionsInRead[cigar_String]:=CountDeletionsInRead[cigar]=CigarDeletions[cigar];

CigarLength[x_String]:=Plus@@(FromDigits/@StringCases[x,md:DigitCharacter..~~("M"|"D")->md]);(*CigarLengthBasic/@StringCases[x,DigitCharacter..~~LetterCharacter]//Total*)

CigarDeletions[x_String]:=Plus@@FromDigits/@StringCases[x,dd:(DigitCharacter..)~~"D"->dd];


CutReadSlice::usage="CutReadSlice[seqcoordcigar_List, {coord1_Integer,coord2_Integer}, initialreadlength_Integer:100, FlankingBases\[Rule]{20,20}]
The function selects the reads that bridge over the fragment and trims the read sequences leaving only the sequence above the fragment and a number of flanking bases.
Input: seqcoordcigar is a list of matrices (one matrix per each sample), the matrix has 3 columns: read sequences, the left position of the read alignment to the genome, the reads cigar annotation (columns 10, 4, 6 from sam table). {coord1, coord2} are the coordinates of the fragment, that we want to cut the read slice around it. initialreadlength is the estimation of the max read length. (If the estimation is too small it will be corrected.)
Output: A list (one per sample) of lists of trimmed sequences.
Option FlankingBases gives the number of bases to leave before trimming on the left and on the right.
Last modification: 5 Feb 2015.";
Options[CutReadSlice]={FlankingBases->{20,20}};
CutReadSlice[seqcoordcigar_List,{coord1_Integer,coord2_Integer},
initialreadlength_Integer:100,
OptionsPattern[]]:=Module[{l,flanks,readlength,chosenseqcoordcigar,ends,psok,readspread,seqcoordcigarok,readspreadok,del,leftends,rightends,cutstarts,cutends,seqlengths,again,result},

flanks=OptionValue[FlankingBases];
l=Length[seqcoordcigar];

readlength=initialreadlength;

Label[again];

(*First select sequences that start not too far on the left and not after coord1 to be able to bridge over the fragment*)
chosenseqcoordcigar=Take[#,BoundaryPositions[#[[All,2]],{coord1-Round[1.5readlength],coord1}]]&/@seqcoordcigar;

(*Calculate from cigar how many bases in the genome the read spands.
GetGenomicSpreadOfRead is basically CigarLength but it remembers its values*)
readspread=Map[GetGenomicSpreadOfRead,chosenseqcoordcigar[[All,All,3]],{2}];

ends=chosenseqcoordcigar[[All,All,2]]+readspread;

(*The right position of the read must fall after coord2*)
psok=Join@@Position[Sign[#-coord2],1,{1},Heads->False]&/@ends;
seqcoordcigarok=Table[chosenseqcoordcigar[[j,psok[[j]]]],{j,1,l}];
readspreadok=Table[readspread[[j,psok[[j]]]],{j,1,l}];

seqlengths=(StringLength/@seqcoordcigarok[[All,All,1]]);

(*If the reads are longer than the initial istimate one should redo the previous analysis*)
If[Max[seqlengths]>1.1readlength,readlength=Max[seqlengths];Goto[again]];

(*Number of deleted bases should be substracted later from the number of bases to trim. CountDeletionsInRead is CigarDeletions, but remembers its values.*)
del=Map[CountDeletionsInRead,seqcoordcigarok[[All,All,3]],{2}];

leftends=(coord1-flanks[[1]]+1)-del-seqcoordcigarok[[All,All,2]];

rightends=(coord2+flanks[[2]]+1)+del-seqcoordcigarok[[All,All,2]]-readspreadok;

cutstarts=Map[Max[1,#]&,leftends,{2}];

cutends=Map[Min[0,#]&,rightends,{2}]+seqlengths(*readlength*);

result=Table[StringTake[#[[1]],#[[2;;3]]]&/@Transpose[{seqcoordcigarok[[j,All,1]],cutstarts[[j]],cutends[[j]]}],{j,1,l}];

Remove[l,flanks,readlength,chosenseqcoordcigar,ends,psok,readspread,seqcoordcigarok,readspreadok,del,leftends,rightends,cutstarts,cutends,seqlengths,again];

result
];


CallVariants::usage=
"CallVariants[bamfiles_, outputvcffile_String, targets_:\"\", region_:\"\", FailedLogFileName\[Rule]Automatic, LogFileName->Automatic]
The function calls variants and saves them in a vcf file.
Input: bamfiles is a list of bam files (one individual per each bam file) or a string like \"*.bam\" or \"D????_duplmarked.bam\" that is converted to a list of files using unix command 'ls'.
targets is a list of regions in the form accepted by ScanForVariantCandidates.
outputvcffile is the name of the file to save the variants in.
 Output: the total number of variants (lines in the VCF file) detected.";
Options[CallVariants]={(*SampleLabels\[Rule]"FromFileNames"*)FailedLogFileName->Automatic,LogFileName->Automatic,OptimiseTargets->True};
CallVariants[bamfiles_,outputvcffile_String,targets0_:"",region0_:"",optns:OptionsPattern[{LoadBedTargets,FindAllelesAndCountReads,ScanForVariantCandidates,GetReadsFromBamFiles,GetSequenceFromGenomeFasta,Split2D,CallVariants,OptimiseTargets,OptimiseTargetsChromosome}]]:=Module[{flbam,samples,header,stream,res,vcflines,problems,strng,problemfile,problemstream,varcount,logfile,logstream,coveragefile,region,samtoolscheck,tm,tm0,targets,optimisedtargets,optnstoreport,outputvcffilekeepall,keepallstream,vcflinesnofake,vcflinesnofakepass,vcfmeta},

optnstoreport={FastaFileName,ExtendTargetsBy,MinimalCoverage,MinimalRatioNonreferenceReads,MinimalNumberNonreferenceReads,MinimalBaseSequencingScore,MinimalReadMappingScore,SamtoolsFlagFilter,SaveCoverage,LogFileName,FailedLogFileName};

tm0=DateList[];

If[$OperatingSystem==="Windows",PrintError["Sorry TidyVar doesn't work under Windows operating system, please try it on Linux or MacOS.\nAborting."];Abort[]];

samtoolscheck=RunExternal[SamtoolsPath<>"samtools --version 2>&1"];
If[Not[And@@StringFreeQ[samtoolscheck,"not found"]],PrintError["samtools not found!\nAborting."];Abort[]];

Switch[bamfiles,_List,flbam=bamfiles,_String,flbam=ReadList["!ls "<>bamfiles,String],_,Return["The bam files are ill-defined"]];

varcount=0;
samples=FileBaseName/@flbam;

coveragefile=OptionValue[SaveCoverage];

If[coveragefile,coveragefile=AppendFileName[outputvcffile,".coverage","txt"]];

If[And[StringQ[coveragefile],FileExistsQ[coveragefile]],RenameFileForced[coveragefile,AppendFileName[coveragefile,".old"],KeepOldFile->False]];
If[StringQ[coveragefile],WriteString[coveragefile,StringJoinWith[Join[{"#CHROM","POS"},samples],"\t"],"\n"];Close[coveragefile]];

stream=OpenWrite[outputvcffile];

outputvcffilekeepall=AppendFileName[outputvcffile,".KeepAll","vcf"];

keepallstream=OpenWrite[outputvcffilekeepall];

problemfile=Switch[OptionValue[FailedLogFileName],Automatic,AppendFileName[outputvcffile,".failed","txt"],
_String,OptionValue[FailedLogFileName],
__,PrintError["The option value of FailedLogFileName ",OptionValue[FailedLogFileName]," is not recognized.\nIt must be a string or 'Automatic'.\nAborting."];Abort[]];

problemstream=OpenWrite[problemfile];

logfile=Switch[OptionValue[LogFileName],Automatic,AppendFileName[outputvcffile,".log","txt"],
_String,OptionValue[LogFileName],
__,PrintError["The option value of LogFileName ",OptionValue[LogFileName]," is not recognized.\nIt must be a string or 'Automatic'.\nAborting."];Abort[]];

logstream=Switch[logfile,
"stdout","stdout",
"stderr","stderr",
__,OpenWrite[logfile]];

WriteString[logstream,DateString[],"\tTidyVar by Boris Noyvert, Greg Elgar lab.\tVersion ",$TidyVarVersion,"\n"];

WriteString[logstream,DateString[],"\tTidyVar Options: ",StringJoinWith[Table[rrr->OptionValue[rrr],{rrr,optnstoreport}],", "]," .\n"];

WriteString[logstream,DateString[],"\tUsing Wolfram Mathematica.\tVersion ",$Version,"\n"];

WriteString[logstream,DateString[],"\tUsing samtools.\t",StringJoinWith[samtoolscheck,"\t"],"\n"];

WriteString[logstream,DateString[],"\tFound ",Length[flbam]," bam files.\n"];

If[StringQ[targets0],targets=LoadBedTargets[targets0,FilterRules[{optns},Options[LoadBedTargets]]],If[ListQ[targets0[[1]]],targets=targets0,targets={targets0}]];

If[OptionValue[OptimiseTargets],
(WriteString[logstream,DateString[],"\tStarted target optimisation. The number of original targets is ",Length[targets],".\n"];
optimisedtargets=OptimiseTargets[flbam,targets,region0];
WriteString[logstream,DateString[],"\tFinished target optimisation. The number of optimised target regions is ",Length[optimisedtargets],".\n"]),
optimisedtargets=targets];

WriteString[logstream,DateString[],"\tStarted to call variants in ",Length[optimisedtargets]," regions.\n"];

header=StringJoinWith[#,"\t"]&@Join[{"#CHROM","POS","ID","REF","ALT","QUAL","FILTER","INFO","FORMAT"},samples];
vcfmeta=VcfMetaLines[];
WriteString[stream,vcfmeta,"\n",header,"\n"];WriteString[keepallstream,vcfmeta,"\n",header,"\n"];

Do[region=MakeCoordinateString[If[ListQ[#[[2]]],{#[[1]],Min[#[[2]]],Max[#[[2]]]},#]]&@optimisedtargets[[j]];
WriteString[logstream,"=================================================================\n",
tm=DateString[],"\tStarted to process region ",j,".\tCoordinates ",region,"\tNumber of targets: ",If[MatrixQ[optimisedtargets[[j,2]]],Length[optimisedtargets[[j,2]]],1],"\n"];
(res=FindAllelesAndCountReads[flbam,optimisedtargets[[j]],SaveCoverage->coveragefile,LogStream->logstream,FilterRules[{optns},Options/@{FindAllelesAndCountReads,ScanForVariantCandidates,GetReadsFromBamFiles}]]);
(*WriteString[logstream,"Finished FindAllelesAndCountReads\n"];*)
If[res[[1]]=!={},
vcflines=Table[
ConvertVariantToVcfLine[res[[1,jj]],FilterRules[{optns},Options/@{ConvertVariantToVcfLine,Split2D,GenotypeReadCounts}]],{jj,1,res[[1]]//Length}];
strng=StringJoinWith[StringJoinWith[#,"\t"]&/@vcflines,"\n"];
WriteString[keepallstream,strng,"\n"];

vcflinesnofake=RemoveDummyAlleles/@vcflines;
vcflinesnofakepass=Pick[vcflinesnofake,vcflinesnofake[[All,7]],"."];
If[vcflinesnofakepass=!={},
(WriteString[logstream,DateString[],"\tWriting ",vcflinesnofakepass//Length," variants to VCF file.\n"];
strng=StringJoinWith[StringJoinWith[#,"\t"]&/@vcflinesnofakepass,"\n"];
WriteString[stream,strng,"\n"])
];
varcount+=Length[vcflinesnofakepass]
];

If[res[[2]]=!={},
strng=StringJoinWith[StringJoinWith[#,"\t"]&/@((Flatten/@res[[2]])[[All,1;;6]]),"\n"];
WriteString[problemstream,strng,"\n"]
];
WriteString[logstream,DateString[],"\tFinished to process region ",j,".\tCoordinates ",region,".\t",NumberForm[-DateDifference[tm,"Second"][[1]],{10,1},ExponentFunction->(Null&)]," seconds.\n",
"=================================================================\n"];
,{j,1,Length[optimisedtargets]}];

WriteString[logstream,DateString[],"\tFinished to call variants.\tTotal running time ",MyRunningTime[tm0],". Found ",varcount," variant sites.\n"];

Close[stream];
Close[keepallstream];
Close[problemstream];
If[And[logstream=!="stdout",logstream=!="stderr"],Close[logstream]];

Remove[samples,header,stream,res,vcflines,problems,strng,problemfile,problemstream,logfile,logstream,region,samtoolscheck,tm,tm0,targets,optimisedtargets,outputvcffilekeepall,keepallstream,vcflinesnofake,vcflinesnofakepass,vcfmeta];

varcount
];


VcfMetaLines[]:=StringJoinWith[#,"\n"]&@{"##fileformat=VCFv4.2",

"##fileDate="<>DateString[Date[],{"Year", "-","Month","-","Day","|","Hour",":","Minute",":","Second"}],

"##source="<>"TidyVar"<>If[StringQ[$TidyVarVersion],".version"<>$TidyVarVersion,""],

If[StringQ[GenomeFastaFile],"##reference=file://"<>GenomeFastaFile,"##reference=\"Not specified\""],

"##phasing=none",
"##INFO=<ID=AF,Number=A,Type=Float,Description=\"Allele Frequency\">",
"##INFO=<ID=AN,Number=1,Type=Integer,Description=\"Total allele number equal to the number of individuals with defined genotypes times ploidity\">",
"##INFO=<ID=AC,Number=A,Type=Integer,Description=\"Total allele count for each allele in individuals with defined genotypes, AF=AC/AN \">",
"##INFO=<ID=DP,Number=1,Type=Integer,Description=\"Combined (across all samples) number of reads covering the variant\">",
"##INFO=<ID=DM,Number=1,Type=String,Description=\"Dummy alleles - alleles that are not called in any individual genotype in the cohort, but there are still reads supporting them\">",

"##FORMAT=<ID=GT,Number=1,Type=String,Description=\"Genotype\">",
"##FORMAT=<ID=AD,Number=R,Type=Integer,Description=\"Allelic depths (number of reads supporting the allele) for the reference and alternative alleles in the order listed\">",
"##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\"Read Depth - sum of AD\">",
"##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\"Genotype Quality - minimal nonzero PL\">",
"##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\"Phred likelihoods for all possible genotypes\">"};


MyRunningTime[tm_]:=Module[{dd},
dd=DateDifference[tm,"Hour"];
If[-dd[[1]]>1,Return[ToString[NumberForm[-dd[[1]],{10,2},ExponentFunction->(Null&)]]<>" hours"]];

dd=DateDifference[tm,"Minute"];
If[-dd[[1]]>1,Return[ToString[NumberForm[-dd[[1]],{10,2},ExponentFunction->(Null&)]]<>" minutes"]];

dd=DateDifference[tm,"Second"];
ToString[NumberForm[-dd[[1]],{10,1},ExponentFunction->(Null&)]]<>" seconds"
];


RegionOnTargets::usage="Returns those targets that are within {region[[1]],region[[2]]},
cuts the targets if necessary. If targets is empty ({{}}) returns the region itself.
Examples:
RegionOnTargets[{5,76},{{0,10},{20,30},{40,50},{60,70},{80,90}}] gives {{5,10},{20,30},{40,50},{60,70}},
RegionOnTargets[{5,8},{{0,10},{20,30},{40,50},{60,70},{80,90}}] gives {{5,8}},
RegionOnTargets[{105,108},{{0,10},{20,30},{40,50},{60,70},{80,90}}] gives{}.";
RegionOnTargets[region_List,targets_?MatrixQ]:=Module[{boundarypos,res},
If[targets==={{}},Return[{region}]];
boundarypos=BoundaryPositions[Join@@targets,region];
res=targets[[Range[Ceiling[(boundarypos[[1]]+1)/2],Floor[boundarypos[[2]]/2]]]];
If[EvenQ[boundarypos[[1]]],

If[boundarypos.{-1,1}===-1,Return[{region}]];PrependTo[res,{region[[1]],targets[[boundarypos[[1]]/2,2]]}]];
If[OddQ[boundarypos[[2]]],AppendTo[res,{targets[[(boundarypos[[2]]+1)/2,1]],region[[2]]}]];
res
];


ReadsByChromosomeBam::usage="ReadsByChromosomeBam[bamfile_String]
The function uses samtools idxstats to get a list of chromosomes and the number of reads mapped to each chromosome and the chromosome size.
Input: bam file name.
Output: {{chr1, Nreads(chr1)},{chr2, Nreads(chr2)},...}";
ReadsByChromosomeBam[bamfile_String]:=Module[{inputfile,cmd},

cmd=StringJoinWith[{SamtoolsPath<>"samtools idxstats",bamfile}];

RunExternal[cmd,{"Word","Number","Number","Number"}][[All,{1,3,2}]]
];


Options[ReadLengthInBam]={SamtoolsFlagFilter->"0x704",MinimalReadMappingScore->0};ReadLengthInBam[bamfile_String,inputregion_:"",firstreads_Integer:1000,OptionsPattern[ReadLengthInBam]]:=Module[{cmd,region,reads},

region=inputregion//MakeCoordinateString;

cmd=StringJoinWith[{SamtoolsPath<>"samtools view", 
If[OptionValue[SamtoolsFlagFilter]===0,"",{"-F",OptionValue[SamtoolsFlagFilter]}],
If[OptionValue[MinimalReadMappingScore]===0,"",{"-q",OptionValue[MinimalReadMappingScore]}],
bamfile,region,
"|",
"head -n",firstreads,
"|",
"awk ' {print $10} '"}];
reads=RunExternal[cmd,String];
StringLength[reads]//Max
];


Options[IndexBamUniform]={JumpNumberReads->1000,SamtoolsFlagFilter->"0x704",MinimalReadMappingScore->0};IndexBamUniform[bamfile_String,inputregion_,OptionsPattern[IndexBamUniform]]:=Module[{cmd,region,numberofreads},

numberofreads=OptionValue[JumpNumberReads];
region=inputregion//MakeCoordinateString;

cmd=StringJoinWith[{SamtoolsPath<>"samtools view", 
If[OptionValue[SamtoolsFlagFilter]===0,"",{"-F",OptionValue[SamtoolsFlagFilter]}],
If[OptionValue[MinimalReadMappingScore]===0,"",{"-q",OptionValue[MinimalReadMappingScore]}],
bamfile,region,
"|",
"awk 'NR %",numberofreads," == 1 {print $3,$4} END {print $3,$4}'"}];
RunExternal[cmd,{Word,Number}]
];


Options[OptimiseTargets]={MemoryCoefficient->1};OptimiseTargets[bamfiles_List,targets_List,inputregion_,optns:OptionsPattern[{OptimiseTargets,OptimiseTargetsChromosome,IndexBamUniform}]]:=Module[{l,readschr,totalreads,readnumbercoef,mdl,regionchrlist,region,chrtargetps,targetschr,regionandtargetsdefined,chrlistps,indx,readlength,step,rl,result},

region=If[StringQ[inputregion],ExtractCoordinatesFromString[inputregion],
Flatten[List[inputregion]]];
If[And[Length[region]>=1,Not[StringQ[region[[1]]]]],region=ReplacePart[region,1->ToString[region[[1]]]]];

If[And[Length[region]>=3,region[[2;;3]].{-1,1}<OptionValue[DontSplitSize]],If[Flatten[targets]==={},Return[{region}],Return[{region[[1]],RegionOnTargets[region[[2;;3]],Pick[targets,targets[[All,1]],region[[1]]][[All,2;;3]]]}]]];

l=Length[bamfiles];
readschr=Cases[ReadsByChromosomeBam[#],x_/;First[x]=!="*"]&/@bamfiles;

regionandtargetsdefined={region=!={},Flatten[targets]=!={}};

Switch[regionandtargetsdefined,

{False,False},
(regionchrlist=List/@readschr[[1,All,1]];
targetschr=ConstantArray[{{}},Length[regionchrlist]]),

{True,False},
(regionchrlist={region};
targetschr={{{}}}),

{False,True},
(chrtargetps=IntersectionPositionsSimple[readschr[[1,All,1]],DeleteDuplicates[targets[[All,1]]]];
targetschr=GatherBy[targets,First][[chrtargetps[[All,2]]]];
regionchrlist=Table[{rrr[[1,1]],Min[rrr[[All,2;;3]]],Max[rrr[[All,2;;3]]]},{rrr,targetschr}]),

{True,True},
(targetschr={Pick[targets,targets[[All,1]],region[[1]]]};
If[Flatten[targetschr]==={},Return[{}]];
regionchrlist={region})
];

If[regionchrlist==={},Return[{}]];

chrlistps=IntersectionPositionsSimple[readschr[[1,All,1]],regionchrlist[[All,1]]][[All,1]];

totalreads=Total[readschr[[All,chrlistps,2]],{2}];
mdl=Ordering[totalreads][[Ceiling[l/2]]];

readnumbercoef=N[totalreads/totalreads[[mdl]]];
readlength=ReadLengthInBam[bamfiles[[mdl]]];
step=Round[OptionValue[MemoryCoefficient]3. 10^8/readlength/Total[readnumbercoef]];

rl=FilterRules[{optns},Options/@{OptimiseTargetsChromosome,IndexBamUniform}];
result=Join@@Table[OptimiseTargetsChromosome[bamfiles[[mdl]],If[Flatten[targetschr[[j]]]==={},{{}},targetschr[[j,All,2;;3]]],regionchrlist[[j]],step,rl,AnticipatedReadLength->readlength],{j,1,Length[regionchrlist]}];

Remove[l,readschr,totalreads,readnumbercoef,mdl,regionchrlist,region,chrtargetps,targetschr,regionandtargetsdefined,chrlistps,indx,readlength,step,rl];

result
];


LoadBedTargets::usage="LoadBedTargets[targetbedfile_String, ExtendTargetsBy\[Rule]0]].
Loads the first 3 columns from a bed file, converts to intervals by adding 1 to the first coordinate, adds to each interval ExtendByBases on both sides, and then merges overlapping intervals.
Output: a list of intervals in the form {chr (String), coord1 (Integer), coord2 (Integer)}.";
Options[LoadBedTargets]={ExtendTargetsBy->0};
LoadBedTargets[targetbedfile_String,OptionsPattern[{LoadBedTargets}]]:=Module[{extendbases,bed,addcoordinates},

If[StringTrim[targetbedfile]==="",Return[{}]];

extendbases=OptionValue[ExtendTargetsBy];

bed=RunExternal["cut -f 1,2,3 "<>targetbedfile,{Word,Number,Number}];
addcoordinates={1,0}+extendbases{-1,1};

Join@@Table[Prepend[#,rrr[[1,1]]]&/@CombineRegions[(addcoordinates+#)&/@rrr[[All,2;;3]]],{rrr,GatherBy[bed,First]}]
];


SplitRegions[regions_?MatrixQ,DistanceToSplit_Integer:1000000]:=Module[{dist,ps},
dist=regions[[2;;-1,1]]-regions[[1;;-2,2]];
ps=Join@@Position[Sign[dist-DistanceToSplit],1,{1},Heads->False];
Take[regions,#]&/@Transpose[{Prepend[ps+1,1],Append[ps,Length[regions]]}]
];


Options[OptimiseTargetsChromosome]={DontSplitSize->1000,SplitGap->2000000,AnticipatedReadLength->300};
OptimiseTargetsChromosome[bamfile_String,targetsonchr0_?MatrixQ,inputregion_List,step_Integer,optns:OptionsPattern[{OptimiseTargetsChromosome,IndexBamUniform}]]:=Module[{chr,indx,targetsonchr,targetsplit,splitregions,splitregionboundaryps,splitregioncounts,fl,qntl,regs,ttt},
chr=inputregion[[1]];

targetsonchr=If[Length[inputregion]>=3,RegionOnTargets[inputregion[[2;;3]],targetsonchr0],targetsonchr0];

If[And[Length[inputregion]>=3,inputregion[[2;;3]].{-1,1}<OptionValue[DontSplitSize]],Return[{chr,targetsonchr}]];

indx=IndexBamUniform[bamfile,inputregion,FilterRules[{optns},Options[IndexBamUniform]]][[All,2]];
If[Flatten[targetsonchr]==={},
(splitregions={{Min[indx],Max[indx]+Round[1.2OptionValue[AnticipatedReadLength]]}};
targetsplit={splitregions}),
(targetsplit=SplitRegions[targetsonchr,OptionValue[SplitGap]];
splitregions={Min[#],Max[#]}&/@targetsplit)];

splitregionboundaryps=BoundaryPositions[indx,#]&/@splitregions;
splitregioncounts=((splitregionboundaryps.{-1,1}+1));
ttt=Table[fl=Floor[splitregioncounts[[j]]/step OptionValue[JumpNumberReads]];
If[fl===0,{{chr,targetsplit[[j]]}},
(qntl=Quantile[Take[indx,splitregionboundaryps[[j]]],Range[fl]/(fl+1)];
regs=Join[{{splitregions[[j,1]],qntl[[1]]-1}},({0,-1}+#)&/@Partition[qntl,2,1],{{qntl[[-1]],splitregions[[j,-1]]}}];
{chr,RegionOnTargets[#,targetsplit[[j]]]}&/@regs)],
{j,1,Length[splitregions]}];
Join@@ttt

];


Options[CheckSamtoolsIsInstalled]={OutputStream->"stdout"};
CheckSamtoolsIsInstalled[path_String:"",OptionsPattern[CheckSamtoolsIsInstalled]]:=Module[{check},
check=RunExternal[path<>"samtools --version 2>&1"];
If[OptionValue[OutputStream]=!="",WriteString[OptionValue[OutputStream],StringJoinWith[check,"\n"],"\n"]];
And@@StringFreeQ[check,{"not found","Permission denied","not recognized"},IgnoreCase->True]
];


Options[CheckBamIsIndexed]={OutputStream->"stdout"};
CheckBamIsIndexed[bamfile_String,OptionsPattern[CheckBamIsIndexed]]:=Module[{readhead,headchr,tryregion,check},
readhead=RunExternal[SamtoolsPath<>"samtools view -H "<>bamfile<>" | head"];
headchr=Flatten[StringCases[readhead,(*"SN:"~~(yyy:WordCharacter..)*)"SN:"~~(yyy__)~~"\tLN":>yyy]];
tryregion=If[Length[headchr]===0,"chr1",MakeCoordinateString[{headchr[[1]],1,2}]];
check=RunExternal[StringJoinWith[{SamtoolsPath<>"samtools view",bamfile,tryregion,"2>&1 | head -n 3"}]];
If[OptionValue[OutputStream]=!="",WriteString[OptionValue[OutputStream],StringJoinWith[{bamfile,check},"\n"],"\n"]];
And@@StringFreeQ[check,{"failed","indexed"},IgnoreCase->True]
];


CheckBamFiles[bamfiles_]:=Module[{flbam,l},
Switch[bamfiles,_List,flbam=bamfiles,_String,flbam=ReadList["!ls "<>bamfiles,String],_,PrintError["The bam files are ill-defined"];Return[False]];
l=Length[flbam];
WriteString["stdout","Found ",l," bam files.\n"];
If[l===0,PrintError["The bam files are ill-defined.\nAborting!"];Abort[]];
If[l>5,
(WriteString["stdout","Checking the indexes of 5 random bam files.\n"];Return[And@@(CheckBamIsIndexed/@RandomSample[flbam,5])]),
(WriteString["stdout","Checking the indexes of bam files.\n"];Return[And@@(CheckBamIsIndexed/@flbam)])]
]


SamtoolsPath="";


TidyVarTmpDirectory=FileNameJoin[{$TemporaryDirectory,"TidyVar"}];
If[Not[DirectoryQ[TidyVarTmpDirectory]],CreateDirectory[TidyVarTmpDirectory]];


End[];


EndPackage[];
